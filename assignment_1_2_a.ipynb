{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19e1f55-488a-4767-83e6-570e6d171fd2",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac9caae0-7e18-4448-a07e-56757280c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "# Load and preprocess the Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 128\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c383a4-77d4-43d4-b875-d2490e461101",
   "metadata": {},
   "source": [
    "## 1: Deep MLP with Increased Dropout\n",
    "This setup focuses on more layers with increased dropout to prevent overfitting, along with the HeNormal initialiser to stabilise the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0eac50-2192-47b6-aefd-af79983b86be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - Precision: 0.8092 - Recall: 0.6192 - accuracy: 0.7173 - loss: 0.7896 - mean_squared_error: 0.0381 - top_k_categorical_accuracy: 0.9738 - val_Precision: 0.8632 - val_Recall: 0.7857 - val_accuracy: 0.8248 - val_loss: 0.4811 - val_mean_squared_error: 0.0250 - val_top_k_categorical_accuracy: 0.9963\n",
      "Epoch 2/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8816 - Recall: 0.7986 - accuracy: 0.8403 - loss: 0.4402 - mean_squared_error: 0.0225 - top_k_categorical_accuracy: 0.9959 - val_Precision: 0.8908 - val_Recall: 0.8177 - val_accuracy: 0.8530 - val_loss: 0.3992 - val_mean_squared_error: 0.0206 - val_top_k_categorical_accuracy: 0.9969\n",
      "Epoch 3/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.8916 - Recall: 0.8238 - accuracy: 0.8568 - loss: 0.3910 - mean_squared_error: 0.0203 - top_k_categorical_accuracy: 0.9972 - val_Precision: 0.8878 - val_Recall: 0.8311 - val_accuracy: 0.8580 - val_loss: 0.3810 - val_mean_squared_error: 0.0197 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 4/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.8944 - Recall: 0.8317 - accuracy: 0.8632 - loss: 0.3721 - mean_squared_error: 0.0193 - top_k_categorical_accuracy: 0.9972 - val_Precision: 0.8914 - val_Recall: 0.8413 - val_accuracy: 0.8678 - val_loss: 0.3783 - val_mean_squared_error: 0.0194 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 5/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.8997 - Recall: 0.8456 - accuracy: 0.8722 - loss: 0.3502 - mean_squared_error: 0.0183 - top_k_categorical_accuracy: 0.9978 - val_Precision: 0.9059 - val_Recall: 0.8417 - val_accuracy: 0.8747 - val_loss: 0.3459 - val_mean_squared_error: 0.0180 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 6/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9014 - Recall: 0.8489 - accuracy: 0.8743 - loss: 0.3392 - mean_squared_error: 0.0178 - top_k_categorical_accuracy: 0.9980 - val_Precision: 0.8975 - val_Recall: 0.8501 - val_accuracy: 0.8721 - val_loss: 0.3513 - val_mean_squared_error: 0.0181 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 7/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9049 - Recall: 0.8534 - accuracy: 0.8788 - loss: 0.3317 - mean_squared_error: 0.0174 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9027 - val_Recall: 0.8578 - val_accuracy: 0.8789 - val_loss: 0.3360 - val_mean_squared_error: 0.0174 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 8/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9070 - Recall: 0.8609 - accuracy: 0.8837 - loss: 0.3156 - mean_squared_error: 0.0166 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.9026 - val_Recall: 0.8491 - val_accuracy: 0.8751 - val_loss: 0.3436 - val_mean_squared_error: 0.0179 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 9/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9100 - Recall: 0.8640 - accuracy: 0.8870 - loss: 0.3062 - mean_squared_error: 0.0162 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9014 - val_Recall: 0.8585 - val_accuracy: 0.8779 - val_loss: 0.3390 - val_mean_squared_error: 0.0173 - val_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 10/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.9128 - Recall: 0.8699 - accuracy: 0.8904 - loss: 0.2993 - mean_squared_error: 0.0157 - top_k_categorical_accuracy: 0.9984 - val_Precision: 0.9068 - val_Recall: 0.8614 - val_accuracy: 0.8820 - val_loss: 0.3279 - val_mean_squared_error: 0.0168 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 11/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9105 - Recall: 0.8693 - accuracy: 0.8899 - loss: 0.2967 - mean_squared_error: 0.0156 - top_k_categorical_accuracy: 0.9985 - val_Precision: 0.8995 - val_Recall: 0.8576 - val_accuracy: 0.8764 - val_loss: 0.3433 - val_mean_squared_error: 0.0174 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 12/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.9117 - Recall: 0.8722 - accuracy: 0.8915 - loss: 0.2920 - mean_squared_error: 0.0155 - top_k_categorical_accuracy: 0.9986 - val_Precision: 0.8968 - val_Recall: 0.8656 - val_accuracy: 0.8796 - val_loss: 0.3320 - val_mean_squared_error: 0.0170 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 13/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9116 - Recall: 0.8721 - accuracy: 0.8914 - loss: 0.2876 - mean_squared_error: 0.0154 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9123 - val_Recall: 0.8625 - val_accuracy: 0.8874 - val_loss: 0.3120 - val_mean_squared_error: 0.0162 - val_top_k_categorical_accuracy: 0.9986\n",
      "Epoch 14/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.9158 - Recall: 0.8776 - accuracy: 0.8956 - loss: 0.2806 - mean_squared_error: 0.0148 - top_k_categorical_accuracy: 0.9988 - val_Precision: 0.9078 - val_Recall: 0.8659 - val_accuracy: 0.8845 - val_loss: 0.3228 - val_mean_squared_error: 0.0166 - val_top_k_categorical_accuracy: 0.9983\n",
      "Epoch 15/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9177 - Recall: 0.8820 - accuracy: 0.8997 - loss: 0.2683 - mean_squared_error: 0.0143 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9052 - val_Recall: 0.8618 - val_accuracy: 0.8829 - val_loss: 0.3266 - val_mean_squared_error: 0.0167 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 16/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - Precision: 0.9156 - Recall: 0.8787 - accuracy: 0.8966 - loss: 0.2734 - mean_squared_error: 0.0146 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9091 - val_Recall: 0.8671 - val_accuracy: 0.8863 - val_loss: 0.3212 - val_mean_squared_error: 0.0163 - val_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 17/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9159 - Recall: 0.8813 - accuracy: 0.8986 - loss: 0.2690 - mean_squared_error: 0.0144 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9067 - val_Recall: 0.8696 - val_accuracy: 0.8872 - val_loss: 0.3155 - val_mean_squared_error: 0.0162 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 18/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9171 - Recall: 0.8828 - accuracy: 0.8989 - loss: 0.2654 - mean_squared_error: 0.0143 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9103 - val_Recall: 0.8606 - val_accuracy: 0.8859 - val_loss: 0.3159 - val_mean_squared_error: 0.0163 - val_top_k_categorical_accuracy: 0.9983\n",
      "Epoch 19/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9207 - Recall: 0.8882 - accuracy: 0.9039 - loss: 0.2578 - mean_squared_error: 0.0137 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9103 - val_Recall: 0.8719 - val_accuracy: 0.8915 - val_loss: 0.3156 - val_mean_squared_error: 0.0160 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 20/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9203 - Recall: 0.8882 - accuracy: 0.9032 - loss: 0.2549 - mean_squared_error: 0.0137 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9029 - val_Recall: 0.8738 - val_accuracy: 0.8864 - val_loss: 0.3158 - val_mean_squared_error: 0.0162 - val_top_k_categorical_accuracy: 0.9984\n",
      "Epoch 21/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.9221 - Recall: 0.8914 - accuracy: 0.9063 - loss: 0.2519 - mean_squared_error: 0.0134 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9085 - val_Recall: 0.8684 - val_accuracy: 0.8868 - val_loss: 0.3173 - val_mean_squared_error: 0.0163 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 22/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9245 - Recall: 0.8929 - accuracy: 0.9082 - loss: 0.2485 - mean_squared_error: 0.0132 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9117 - val_Recall: 0.8698 - val_accuracy: 0.8903 - val_loss: 0.3189 - val_mean_squared_error: 0.0159 - val_top_k_categorical_accuracy: 0.9984\n",
      "Epoch 23/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9234 - Recall: 0.8954 - accuracy: 0.9094 - loss: 0.2415 - mean_squared_error: 0.0130 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9056 - val_Recall: 0.8737 - val_accuracy: 0.8889 - val_loss: 0.3169 - val_mean_squared_error: 0.0158 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 24/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9244 - Recall: 0.8941 - accuracy: 0.9087 - loss: 0.2449 - mean_squared_error: 0.0132 - top_k_categorical_accuracy: 0.9993 - val_Precision: 0.9093 - val_Recall: 0.8737 - val_accuracy: 0.8904 - val_loss: 0.3202 - val_mean_squared_error: 0.0159 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 25/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9247 - Recall: 0.8941 - accuracy: 0.9084 - loss: 0.2429 - mean_squared_error: 0.0131 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9107 - val_Recall: 0.8791 - val_accuracy: 0.8926 - val_loss: 0.3070 - val_mean_squared_error: 0.0153 - val_top_k_categorical_accuracy: 0.9986\n",
      "Test loss: 0.30698493123054504\n",
      "Test accuracy: 0.8925999999046326\n",
      "Test precision: 0.910701334476471\n",
      "Test recall: 0.8791000247001648\n",
      "Test top-K categorical accuracy: 0.9986000061035156\n",
      "Test mean squared error: 0.015280909836292267\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', kernel_initializer=HeNormal(), input_shape=(784,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu', kernel_initializer=HeNormal()),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu', kernel_initializer=HeNormal()),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy', 'mean_squared_error']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])\n",
    "print('Test mean squared error:', score[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcff0b2-7132-48f3-a9dd-41de5dcf140f",
   "metadata": {},
   "source": [
    "## 2: Simplified MLP with ELU Activation and RMSprop Optimizer\n",
    "This architecture uses the ELU activation function, which can often improve gradient flow, and the RMSprop optimiser, which sometimes performs better on classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "503cf32f-cfa5-45e5-8a4d-30e521a03c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Precision: 0.7707 - Recall: 0.6655 - accuracy: 0.7165 - loss: 0.8437 - mean_squared_error: 0.0393 - top_k_categorical_accuracy: 0.9778 - val_Precision: 0.8579 - val_Recall: 0.8033 - val_accuracy: 0.8260 - val_loss: 0.4923 - val_mean_squared_error: 0.0245 - val_top_k_categorical_accuracy: 0.9954\n",
      "Epoch 2/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8598 - Recall: 0.7941 - accuracy: 0.8253 - loss: 0.4805 - mean_squared_error: 0.0244 - top_k_categorical_accuracy: 0.9952 - val_Precision: 0.8710 - val_Recall: 0.8132 - val_accuracy: 0.8389 - val_loss: 0.4575 - val_mean_squared_error: 0.0227 - val_top_k_categorical_accuracy: 0.9950\n",
      "Epoch 3/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8783 - Recall: 0.8175 - accuracy: 0.8460 - loss: 0.4249 - mean_squared_error: 0.0217 - top_k_categorical_accuracy: 0.9970 - val_Precision: 0.8961 - val_Recall: 0.8239 - val_accuracy: 0.8596 - val_loss: 0.4038 - val_mean_squared_error: 0.0203 - val_top_k_categorical_accuracy: 0.9966\n",
      "Epoch 4/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8823 - Recall: 0.8255 - accuracy: 0.8532 - loss: 0.4055 - mean_squared_error: 0.0207 - top_k_categorical_accuracy: 0.9969 - val_Precision: 0.8861 - val_Recall: 0.8436 - val_accuracy: 0.8617 - val_loss: 0.3972 - val_mean_squared_error: 0.0197 - val_top_k_categorical_accuracy: 0.9967\n",
      "Epoch 5/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.8923 - Recall: 0.8383 - accuracy: 0.8634 - loss: 0.3785 - mean_squared_error: 0.0194 - top_k_categorical_accuracy: 0.9974 - val_Precision: 0.8860 - val_Recall: 0.8413 - val_accuracy: 0.8606 - val_loss: 0.3949 - val_mean_squared_error: 0.0198 - val_top_k_categorical_accuracy: 0.9971\n",
      "Epoch 6/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8951 - Recall: 0.8417 - accuracy: 0.8667 - loss: 0.3710 - mean_squared_error: 0.0189 - top_k_categorical_accuracy: 0.9973 - val_Precision: 0.8725 - val_Recall: 0.8188 - val_accuracy: 0.8442 - val_loss: 0.4434 - val_mean_squared_error: 0.0221 - val_top_k_categorical_accuracy: 0.9964\n",
      "Epoch 7/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8982 - Recall: 0.8471 - accuracy: 0.8703 - loss: 0.3618 - mean_squared_error: 0.0184 - top_k_categorical_accuracy: 0.9973 - val_Precision: 0.8906 - val_Recall: 0.8438 - val_accuracy: 0.8643 - val_loss: 0.3813 - val_mean_squared_error: 0.0191 - val_top_k_categorical_accuracy: 0.9971\n",
      "Epoch 8/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9023 - Recall: 0.8534 - accuracy: 0.8766 - loss: 0.3497 - mean_squared_error: 0.0177 - top_k_categorical_accuracy: 0.9978 - val_Precision: 0.8901 - val_Recall: 0.8387 - val_accuracy: 0.8623 - val_loss: 0.3725 - val_mean_squared_error: 0.0192 - val_top_k_categorical_accuracy: 0.9972\n",
      "Epoch 9/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9018 - Recall: 0.8518 - accuracy: 0.8761 - loss: 0.3421 - mean_squared_error: 0.0176 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.8934 - val_Recall: 0.8442 - val_accuracy: 0.8670 - val_loss: 0.3832 - val_mean_squared_error: 0.0192 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 10/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9043 - Recall: 0.8582 - accuracy: 0.8807 - loss: 0.3361 - mean_squared_error: 0.0171 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.8792 - val_Recall: 0.8514 - val_accuracy: 0.8630 - val_loss: 0.3934 - val_mean_squared_error: 0.0195 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 11/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.9058 - Recall: 0.8594 - accuracy: 0.8824 - loss: 0.3332 - mean_squared_error: 0.0169 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.8825 - val_Recall: 0.8332 - val_accuracy: 0.8543 - val_loss: 0.4030 - val_mean_squared_error: 0.0202 - val_top_k_categorical_accuracy: 0.9964\n",
      "Epoch 12/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9069 - Recall: 0.8617 - accuracy: 0.8843 - loss: 0.3270 - mean_squared_error: 0.0167 - top_k_categorical_accuracy: 0.9979 - val_Precision: 0.9058 - val_Recall: 0.8351 - val_accuracy: 0.8697 - val_loss: 0.3854 - val_mean_squared_error: 0.0189 - val_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 13/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - Precision: 0.9064 - Recall: 0.8610 - accuracy: 0.8821 - loss: 0.3262 - mean_squared_error: 0.0166 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.8915 - val_Recall: 0.8454 - val_accuracy: 0.8671 - val_loss: 0.4139 - val_mean_squared_error: 0.0192 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 14/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - Precision: 0.9104 - Recall: 0.8633 - accuracy: 0.8862 - loss: 0.3297 - mean_squared_error: 0.0164 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9032 - val_Recall: 0.8466 - val_accuracy: 0.8757 - val_loss: 0.3786 - val_mean_squared_error: 0.0183 - val_top_k_categorical_accuracy: 0.9969\n",
      "Epoch 15/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9106 - Recall: 0.8687 - accuracy: 0.8891 - loss: 0.3160 - mean_squared_error: 0.0160 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.8691 - val_Recall: 0.8291 - val_accuracy: 0.8462 - val_loss: 0.4278 - val_mean_squared_error: 0.0212 - val_top_k_categorical_accuracy: 0.9971\n",
      "Epoch 16/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9112 - Recall: 0.8694 - accuracy: 0.8904 - loss: 0.3199 - mean_squared_error: 0.0160 - top_k_categorical_accuracy: 0.9984 - val_Precision: 0.8907 - val_Recall: 0.8568 - val_accuracy: 0.8716 - val_loss: 0.3929 - val_mean_squared_error: 0.0188 - val_top_k_categorical_accuracy: 0.9969\n",
      "Epoch 17/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - Precision: 0.9116 - Recall: 0.8676 - accuracy: 0.8888 - loss: 0.3189 - mean_squared_error: 0.0159 - top_k_categorical_accuracy: 0.9985 - val_Precision: 0.8955 - val_Recall: 0.8428 - val_accuracy: 0.8675 - val_loss: 0.3831 - val_mean_squared_error: 0.0185 - val_top_k_categorical_accuracy: 0.9963\n",
      "Epoch 18/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9128 - Recall: 0.8670 - accuracy: 0.8886 - loss: 0.3178 - mean_squared_error: 0.0161 - top_k_categorical_accuracy: 0.9984 - val_Precision: 0.9084 - val_Recall: 0.8538 - val_accuracy: 0.8792 - val_loss: 0.3740 - val_mean_squared_error: 0.0175 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 19/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - Precision: 0.9146 - Recall: 0.8724 - accuracy: 0.8926 - loss: 0.3090 - mean_squared_error: 0.0154 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.9005 - val_Recall: 0.8632 - val_accuracy: 0.8798 - val_loss: 0.3639 - val_mean_squared_error: 0.0171 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 20/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - Precision: 0.9161 - Recall: 0.8726 - accuracy: 0.8932 - loss: 0.3060 - mean_squared_error: 0.0153 - top_k_categorical_accuracy: 0.9980 - val_Precision: 0.9006 - val_Recall: 0.8504 - val_accuracy: 0.8721 - val_loss: 0.3980 - val_mean_squared_error: 0.0185 - val_top_k_categorical_accuracy: 0.9961\n",
      "Epoch 21/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - Precision: 0.9129 - Recall: 0.8676 - accuracy: 0.8895 - loss: 0.3102 - mean_squared_error: 0.0157 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.8932 - val_Recall: 0.8677 - val_accuracy: 0.8787 - val_loss: 0.3933 - val_mean_squared_error: 0.0177 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 22/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - Precision: 0.9162 - Recall: 0.8731 - accuracy: 0.8936 - loss: 0.3067 - mean_squared_error: 0.0153 - top_k_categorical_accuracy: 0.9984 - val_Precision: 0.9080 - val_Recall: 0.8669 - val_accuracy: 0.8856 - val_loss: 0.3580 - val_mean_squared_error: 0.0168 - val_top_k_categorical_accuracy: 0.9971\n",
      "Epoch 23/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9187 - Recall: 0.8771 - accuracy: 0.8977 - loss: 0.3025 - mean_squared_error: 0.0149 - top_k_categorical_accuracy: 0.9987 - val_Precision: 0.8977 - val_Recall: 0.8574 - val_accuracy: 0.8761 - val_loss: 0.3706 - val_mean_squared_error: 0.0175 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 24/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - Precision: 0.9178 - Recall: 0.8748 - accuracy: 0.8955 - loss: 0.2981 - mean_squared_error: 0.0151 - top_k_categorical_accuracy: 0.9985 - val_Precision: 0.8995 - val_Recall: 0.8631 - val_accuracy: 0.8808 - val_loss: 0.3891 - val_mean_squared_error: 0.0175 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 25/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - Precision: 0.9188 - Recall: 0.8749 - accuracy: 0.8960 - loss: 0.3016 - mean_squared_error: 0.0149 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.9038 - val_Recall: 0.8636 - val_accuracy: 0.8825 - val_loss: 0.3942 - val_mean_squared_error: 0.0172 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 26/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - Precision: 0.9216 - Recall: 0.8803 - accuracy: 0.8992 - loss: 0.2923 - mean_squared_error: 0.0144 - top_k_categorical_accuracy: 0.9988 - val_Precision: 0.9109 - val_Recall: 0.8739 - val_accuracy: 0.8911 - val_loss: 0.3640 - val_mean_squared_error: 0.0161 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 27/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - Precision: 0.9174 - Recall: 0.8756 - accuracy: 0.8963 - loss: 0.2934 - mean_squared_error: 0.0148 - top_k_categorical_accuracy: 0.9985 - val_Precision: 0.9012 - val_Recall: 0.8632 - val_accuracy: 0.8806 - val_loss: 0.3774 - val_mean_squared_error: 0.0172 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 28/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - Precision: 0.9190 - Recall: 0.8784 - accuracy: 0.8964 - loss: 0.2996 - mean_squared_error: 0.0148 - top_k_categorical_accuracy: 0.9985 - val_Precision: 0.8937 - val_Recall: 0.8609 - val_accuracy: 0.8755 - val_loss: 0.4232 - val_mean_squared_error: 0.0180 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 29/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9189 - Recall: 0.8775 - accuracy: 0.8981 - loss: 0.2943 - mean_squared_error: 0.0147 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9028 - val_Recall: 0.8569 - val_accuracy: 0.8784 - val_loss: 0.3782 - val_mean_squared_error: 0.0176 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 30/30\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - Precision: 0.9225 - Recall: 0.8817 - accuracy: 0.9016 - loss: 0.2906 - mean_squared_error: 0.0144 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9125 - val_Recall: 0.8656 - val_accuracy: 0.8890 - val_loss: 0.3584 - val_mean_squared_error: 0.0163 - val_top_k_categorical_accuracy: 0.9978\n",
      "Test loss: 0.3584100604057312\n",
      "Test accuracy: 0.8889999985694885\n",
      "Test precision: 0.912502646446228\n",
      "Test recall: 0.8655999898910522\n",
      "Test top-K categorical accuracy: 0.9977999925613403\n",
      "Test mean squared error: 0.016276340931653976\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(512, activation='elu', kernel_initializer=HeNormal(), input_shape=(784,)),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(128, activation='elu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='RMSprop', \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy', 'mean_squared_error']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=30, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])\n",
    "print('Test mean squared error:', score[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156688c-25bc-497f-83f0-9608f14512f9",
   "metadata": {},
   "source": [
    "## 3: Wider MLP with LeakyReLU Activation and SGD Optimizer\n",
    "This option increases the width of each layer and employs LeakyReLU for better gradient flow in deeper networks. It is combined with the SGD optimiser for controlled learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "537ad591-1b05-4088-9a51-0764bb39e3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - Precision: 0.7685 - Recall: 0.4937 - accuracy: 0.6267 - loss: 1.0437 - mean_squared_error: 0.0482 - top_k_categorical_accuracy: 0.9432 - val_Precision: 0.8821 - val_Recall: 0.7679 - val_accuracy: 0.8270 - val_loss: 0.4764 - val_mean_squared_error: 0.0246 - val_top_k_categorical_accuracy: 0.9958\n",
      "Epoch 2/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8675 - Recall: 0.7592 - accuracy: 0.8157 - loss: 0.5206 - mean_squared_error: 0.0262 - top_k_categorical_accuracy: 0.9941 - val_Precision: 0.8874 - val_Recall: 0.8019 - val_accuracy: 0.8450 - val_loss: 0.4284 - val_mean_squared_error: 0.0221 - val_top_k_categorical_accuracy: 0.9966\n",
      "Epoch 3/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.8773 - Recall: 0.7949 - accuracy: 0.8374 - loss: 0.4528 - mean_squared_error: 0.0231 - top_k_categorical_accuracy: 0.9960 - val_Precision: 0.8963 - val_Recall: 0.8110 - val_accuracy: 0.8544 - val_loss: 0.4026 - val_mean_squared_error: 0.0208 - val_top_k_categorical_accuracy: 0.9968\n",
      "Epoch 4/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8863 - Recall: 0.8124 - accuracy: 0.8494 - loss: 0.4154 - mean_squared_error: 0.0213 - top_k_categorical_accuracy: 0.9972 - val_Precision: 0.8966 - val_Recall: 0.8231 - val_accuracy: 0.8596 - val_loss: 0.3883 - val_mean_squared_error: 0.0200 - val_top_k_categorical_accuracy: 0.9968\n",
      "Epoch 5/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8900 - Recall: 0.8242 - accuracy: 0.8578 - loss: 0.3985 - mean_squared_error: 0.0205 - top_k_categorical_accuracy: 0.9968 - val_Precision: 0.8960 - val_Recall: 0.8272 - val_accuracy: 0.8611 - val_loss: 0.3765 - val_mean_squared_error: 0.0196 - val_top_k_categorical_accuracy: 0.9968\n",
      "Epoch 6/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8934 - Recall: 0.8280 - accuracy: 0.8594 - loss: 0.3843 - mean_squared_error: 0.0199 - top_k_categorical_accuracy: 0.9974 - val_Precision: 0.8999 - val_Recall: 0.8301 - val_accuracy: 0.8649 - val_loss: 0.3718 - val_mean_squared_error: 0.0194 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 7/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8962 - Recall: 0.8368 - accuracy: 0.8659 - loss: 0.3695 - mean_squared_error: 0.0191 - top_k_categorical_accuracy: 0.9976 - val_Precision: 0.9003 - val_Recall: 0.8434 - val_accuracy: 0.8707 - val_loss: 0.3560 - val_mean_squared_error: 0.0185 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 8/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8981 - Recall: 0.8432 - accuracy: 0.8697 - loss: 0.3536 - mean_squared_error: 0.0184 - top_k_categorical_accuracy: 0.9969 - val_Precision: 0.9014 - val_Recall: 0.8470 - val_accuracy: 0.8718 - val_loss: 0.3480 - val_mean_squared_error: 0.0181 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 9/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9028 - Recall: 0.8488 - accuracy: 0.8751 - loss: 0.3436 - mean_squared_error: 0.0178 - top_k_categorical_accuracy: 0.9978 - val_Precision: 0.9027 - val_Recall: 0.8413 - val_accuracy: 0.8695 - val_loss: 0.3523 - val_mean_squared_error: 0.0184 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 10/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9016 - Recall: 0.8486 - accuracy: 0.8751 - loss: 0.3391 - mean_squared_error: 0.0177 - top_k_categorical_accuracy: 0.9979 - val_Precision: 0.8981 - val_Recall: 0.8471 - val_accuracy: 0.8729 - val_loss: 0.3482 - val_mean_squared_error: 0.0182 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 11/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.9045 - Recall: 0.8535 - accuracy: 0.8784 - loss: 0.3344 - mean_squared_error: 0.0174 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.9036 - val_Recall: 0.8464 - val_accuracy: 0.8752 - val_loss: 0.3403 - val_mean_squared_error: 0.0178 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 12/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.9058 - Recall: 0.8550 - accuracy: 0.8803 - loss: 0.3269 - mean_squared_error: 0.0171 - top_k_categorical_accuracy: 0.9977 - val_Precision: 0.8995 - val_Recall: 0.8525 - val_accuracy: 0.8747 - val_loss: 0.3381 - val_mean_squared_error: 0.0177 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 13/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.9064 - Recall: 0.8594 - accuracy: 0.8811 - loss: 0.3161 - mean_squared_error: 0.0167 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.8998 - val_Recall: 0.8520 - val_accuracy: 0.8747 - val_loss: 0.3371 - val_mean_squared_error: 0.0177 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 14/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9077 - Recall: 0.8620 - accuracy: 0.8840 - loss: 0.3119 - mean_squared_error: 0.0165 - top_k_categorical_accuracy: 0.9984 - val_Precision: 0.9017 - val_Recall: 0.8544 - val_accuracy: 0.8761 - val_loss: 0.3316 - val_mean_squared_error: 0.0174 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 15/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9076 - Recall: 0.8631 - accuracy: 0.8841 - loss: 0.3101 - mean_squared_error: 0.0164 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.9041 - val_Recall: 0.8565 - val_accuracy: 0.8793 - val_loss: 0.3334 - val_mean_squared_error: 0.0174 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 16/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.9104 - Recall: 0.8676 - accuracy: 0.8879 - loss: 0.3057 - mean_squared_error: 0.0160 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.9036 - val_Recall: 0.8566 - val_accuracy: 0.8797 - val_loss: 0.3319 - val_mean_squared_error: 0.0172 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 17/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.9117 - Recall: 0.8680 - accuracy: 0.8888 - loss: 0.3017 - mean_squared_error: 0.0158 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9021 - val_Recall: 0.8574 - val_accuracy: 0.8811 - val_loss: 0.3253 - val_mean_squared_error: 0.0170 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 18/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9122 - Recall: 0.8706 - accuracy: 0.8898 - loss: 0.2929 - mean_squared_error: 0.0156 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9033 - val_Recall: 0.8623 - val_accuracy: 0.8814 - val_loss: 0.3257 - val_mean_squared_error: 0.0170 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 19/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9134 - Recall: 0.8723 - accuracy: 0.8927 - loss: 0.2902 - mean_squared_error: 0.0154 - top_k_categorical_accuracy: 0.9985 - val_Precision: 0.9033 - val_Recall: 0.8660 - val_accuracy: 0.8837 - val_loss: 0.3183 - val_mean_squared_error: 0.0165 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 20/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.9153 - Recall: 0.8753 - accuracy: 0.8945 - loss: 0.2842 - mean_squared_error: 0.0150 - top_k_categorical_accuracy: 0.9986 - val_Precision: 0.9011 - val_Recall: 0.8606 - val_accuracy: 0.8780 - val_loss: 0.3349 - val_mean_squared_error: 0.0174 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 21/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9147 - Recall: 0.8750 - accuracy: 0.8934 - loss: 0.2864 - mean_squared_error: 0.0151 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9049 - val_Recall: 0.8679 - val_accuracy: 0.8844 - val_loss: 0.3187 - val_mean_squared_error: 0.0165 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 22/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - Precision: 0.9154 - Recall: 0.8780 - accuracy: 0.8963 - loss: 0.2772 - mean_squared_error: 0.0148 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9057 - val_Recall: 0.8668 - val_accuracy: 0.8858 - val_loss: 0.3150 - val_mean_squared_error: 0.0163 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 23/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.9188 - Recall: 0.8822 - accuracy: 0.8988 - loss: 0.2690 - mean_squared_error: 0.0144 - top_k_categorical_accuracy: 0.9988 - val_Precision: 0.9005 - val_Recall: 0.8655 - val_accuracy: 0.8815 - val_loss: 0.3262 - val_mean_squared_error: 0.0168 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 24/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9150 - Recall: 0.8784 - accuracy: 0.8968 - loss: 0.2756 - mean_squared_error: 0.0148 - top_k_categorical_accuracy: 0.9989 - val_Precision: 0.9015 - val_Recall: 0.8655 - val_accuracy: 0.8812 - val_loss: 0.3188 - val_mean_squared_error: 0.0165 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 25/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9176 - Recall: 0.8825 - accuracy: 0.8990 - loss: 0.2701 - mean_squared_error: 0.0144 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9039 - val_Recall: 0.8672 - val_accuracy: 0.8830 - val_loss: 0.3155 - val_mean_squared_error: 0.0166 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 26/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9187 - Recall: 0.8830 - accuracy: 0.9007 - loss: 0.2668 - mean_squared_error: 0.0143 - top_k_categorical_accuracy: 0.9987 - val_Precision: 0.9112 - val_Recall: 0.8709 - val_accuracy: 0.8904 - val_loss: 0.3055 - val_mean_squared_error: 0.0158 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 27/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9205 - Recall: 0.8857 - accuracy: 0.9022 - loss: 0.2590 - mean_squared_error: 0.0139 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9086 - val_Recall: 0.8775 - val_accuracy: 0.8914 - val_loss: 0.3047 - val_mean_squared_error: 0.0157 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 28/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.9233 - Recall: 0.8916 - accuracy: 0.9064 - loss: 0.2512 - mean_squared_error: 0.0134 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9132 - val_Recall: 0.8748 - val_accuracy: 0.8925 - val_loss: 0.3053 - val_mean_squared_error: 0.0158 - val_top_k_categorical_accuracy: 0.9983\n",
      "Epoch 29/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9199 - Recall: 0.8869 - accuracy: 0.9028 - loss: 0.2579 - mean_squared_error: 0.0138 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9056 - val_Recall: 0.8728 - val_accuracy: 0.8879 - val_loss: 0.3100 - val_mean_squared_error: 0.0160 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 30/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.9225 - Recall: 0.8909 - accuracy: 0.9059 - loss: 0.2506 - mean_squared_error: 0.0134 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9014 - val_Recall: 0.8731 - val_accuracy: 0.8859 - val_loss: 0.3084 - val_mean_squared_error: 0.0160 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 31/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9240 - Recall: 0.8927 - accuracy: 0.9071 - loss: 0.2472 - mean_squared_error: 0.0133 - top_k_categorical_accuracy: 0.9993 - val_Precision: 0.9068 - val_Recall: 0.8723 - val_accuracy: 0.8883 - val_loss: 0.3098 - val_mean_squared_error: 0.0160 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 32/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9228 - Recall: 0.8910 - accuracy: 0.9063 - loss: 0.2476 - mean_squared_error: 0.0133 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9049 - val_Recall: 0.8740 - val_accuracy: 0.8880 - val_loss: 0.3184 - val_mean_squared_error: 0.0163 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 33/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9244 - Recall: 0.8933 - accuracy: 0.9080 - loss: 0.2448 - mean_squared_error: 0.0131 - top_k_categorical_accuracy: 0.9988 - val_Precision: 0.9090 - val_Recall: 0.8804 - val_accuracy: 0.8928 - val_loss: 0.3013 - val_mean_squared_error: 0.0154 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 34/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9228 - Recall: 0.8930 - accuracy: 0.9076 - loss: 0.2445 - mean_squared_error: 0.0132 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9103 - val_Recall: 0.8743 - val_accuracy: 0.8902 - val_loss: 0.3029 - val_mean_squared_error: 0.0157 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 35/35\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9254 - Recall: 0.8954 - accuracy: 0.9097 - loss: 0.2384 - mean_squared_error: 0.0128 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9048 - val_Recall: 0.8755 - val_accuracy: 0.8902 - val_loss: 0.3211 - val_mean_squared_error: 0.0162 - val_top_k_categorical_accuracy: 0.9977\n",
      "Test loss: 0.3210947811603546\n",
      "Test accuracy: 0.8902000188827515\n",
      "Test precision: 0.9048160314559937\n",
      "Test recall: 0.8755000233650208\n",
      "Test top-K categorical accuracy: 0.9976999759674072\n",
      "Test mean squared error: 0.016158487647771835\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(1024, kernel_initializer=HeNormal(), input_shape=(784,)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.4),\n",
    "    Dense(512, kernel_initializer=HeNormal()),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, kernel_initializer=HeNormal()),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.4),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=SGD(learning_rate=0.01, momentum=0.9), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy', 'mean_squared_error']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])\n",
    "print('Test mean squared error:', score[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d6514-82de-43bd-a5bd-62f198249d45",
   "metadata": {},
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b748ceab-2fa8-4d49-9c42-51b22c2fa05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.reshape(50000, 32 * 32 * 3).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 32 * 32 * 3).astype('float32') / 255\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 128\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a55dc90-5686-472f-982a-05ba7001d001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - Precision: 0.2795 - Recall: 0.0129 - accuracy: 0.1860 - loss: 2.2772 - mean_squared_error: 0.0893 - top_k_categorical_accuracy: 0.6825 - val_Precision: 0.7064 - val_Recall: 0.0166 - val_accuracy: 0.3203 - val_loss: 1.8684 - val_mean_squared_error: 0.0797 - val_top_k_categorical_accuracy: 0.8319\n",
      "Epoch 2/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.5370 - Recall: 0.0426 - accuracy: 0.2742 - loss: 1.9440 - mean_squared_error: 0.0818 - top_k_categorical_accuracy: 0.7980 - val_Precision: 0.7075 - val_Recall: 0.0237 - val_accuracy: 0.3446 - val_loss: 1.8206 - val_mean_squared_error: 0.0783 - val_top_k_categorical_accuracy: 0.8497\n",
      "Epoch 3/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.5342 - Recall: 0.0492 - accuracy: 0.2954 - loss: 1.9028 - mean_squared_error: 0.0806 - top_k_categorical_accuracy: 0.8112 - val_Precision: 0.7604 - val_Recall: 0.0146 - val_accuracy: 0.3640 - val_loss: 1.8121 - val_mean_squared_error: 0.0780 - val_top_k_categorical_accuracy: 0.8574\n",
      "Epoch 4/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.5613 - Recall: 0.0586 - accuracy: 0.3081 - loss: 1.8730 - mean_squared_error: 0.0797 - top_k_categorical_accuracy: 0.8247 - val_Precision: 0.7421 - val_Recall: 0.0282 - val_accuracy: 0.3630 - val_loss: 1.7828 - val_mean_squared_error: 0.0772 - val_top_k_categorical_accuracy: 0.8626\n",
      "Epoch 5/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.5807 - Recall: 0.0758 - accuracy: 0.3262 - loss: 1.8335 - mean_squared_error: 0.0785 - top_k_categorical_accuracy: 0.8393 - val_Precision: 0.7579 - val_Recall: 0.0263 - val_accuracy: 0.3761 - val_loss: 1.7433 - val_mean_squared_error: 0.0762 - val_top_k_categorical_accuracy: 0.8762\n",
      "Epoch 6/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6196 - Recall: 0.0855 - accuracy: 0.3359 - loss: 1.8157 - mean_squared_error: 0.0778 - top_k_categorical_accuracy: 0.8403 - val_Precision: 0.6492 - val_Recall: 0.0446 - val_accuracy: 0.3673 - val_loss: 1.7397 - val_mean_squared_error: 0.0762 - val_top_k_categorical_accuracy: 0.8719\n",
      "Epoch 7/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.5907 - Recall: 0.0839 - accuracy: 0.3370 - loss: 1.8118 - mean_squared_error: 0.0778 - top_k_categorical_accuracy: 0.8440 - val_Precision: 0.7974 - val_Recall: 0.0370 - val_accuracy: 0.3889 - val_loss: 1.7116 - val_mean_squared_error: 0.0752 - val_top_k_categorical_accuracy: 0.8866\n",
      "Epoch 8/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6140 - Recall: 0.0944 - accuracy: 0.3464 - loss: 1.7838 - mean_squared_error: 0.0769 - top_k_categorical_accuracy: 0.8492 - val_Precision: 0.7211 - val_Recall: 0.0556 - val_accuracy: 0.4022 - val_loss: 1.6943 - val_mean_squared_error: 0.0743 - val_top_k_categorical_accuracy: 0.8878\n",
      "Epoch 9/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.5942 - Recall: 0.0891 - accuracy: 0.3467 - loss: 1.7834 - mean_squared_error: 0.0770 - top_k_categorical_accuracy: 0.8505 - val_Precision: 0.8073 - val_Recall: 0.0398 - val_accuracy: 0.3977 - val_loss: 1.7330 - val_mean_squared_error: 0.0754 - val_top_k_categorical_accuracy: 0.8754\n",
      "Epoch 10/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.5971 - Recall: 0.0957 - accuracy: 0.3508 - loss: 1.7727 - mean_squared_error: 0.0766 - top_k_categorical_accuracy: 0.8548 - val_Precision: 0.7806 - val_Recall: 0.0370 - val_accuracy: 0.3855 - val_loss: 1.7173 - val_mean_squared_error: 0.0753 - val_top_k_categorical_accuracy: 0.8828\n",
      "Epoch 11/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6037 - Recall: 0.0925 - accuracy: 0.3517 - loss: 1.7726 - mean_squared_error: 0.0767 - top_k_categorical_accuracy: 0.8539 - val_Precision: 0.7201 - val_Recall: 0.0548 - val_accuracy: 0.3810 - val_loss: 1.7182 - val_mean_squared_error: 0.0751 - val_top_k_categorical_accuracy: 0.8806\n",
      "Epoch 12/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6160 - Recall: 0.1058 - accuracy: 0.3594 - loss: 1.7526 - mean_squared_error: 0.0760 - top_k_categorical_accuracy: 0.8589 - val_Precision: 0.7059 - val_Recall: 0.0665 - val_accuracy: 0.3920 - val_loss: 1.7191 - val_mean_squared_error: 0.0747 - val_top_k_categorical_accuracy: 0.8714\n",
      "Epoch 13/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6243 - Recall: 0.1059 - accuracy: 0.3645 - loss: 1.7532 - mean_squared_error: 0.0759 - top_k_categorical_accuracy: 0.8594 - val_Precision: 0.7465 - val_Recall: 0.0751 - val_accuracy: 0.4081 - val_loss: 1.6540 - val_mean_squared_error: 0.0729 - val_top_k_categorical_accuracy: 0.8945\n",
      "Epoch 14/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6096 - Recall: 0.1070 - accuracy: 0.3632 - loss: 1.7396 - mean_squared_error: 0.0757 - top_k_categorical_accuracy: 0.8628 - val_Precision: 0.7371 - val_Recall: 0.0555 - val_accuracy: 0.4048 - val_loss: 1.7009 - val_mean_squared_error: 0.0743 - val_top_k_categorical_accuracy: 0.8757\n",
      "Epoch 15/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6142 - Recall: 0.1079 - accuracy: 0.3609 - loss: 1.7497 - mean_squared_error: 0.0758 - top_k_categorical_accuracy: 0.8609 - val_Precision: 0.7272 - val_Recall: 0.0741 - val_accuracy: 0.3935 - val_loss: 1.6804 - val_mean_squared_error: 0.0738 - val_top_k_categorical_accuracy: 0.8863\n",
      "Epoch 16/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - Precision: 0.6175 - Recall: 0.1119 - accuracy: 0.3704 - loss: 1.7391 - mean_squared_error: 0.0755 - top_k_categorical_accuracy: 0.8627 - val_Precision: 0.7858 - val_Recall: 0.0510 - val_accuracy: 0.3984 - val_loss: 1.7137 - val_mean_squared_error: 0.0746 - val_top_k_categorical_accuracy: 0.8780\n",
      "Epoch 17/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - Precision: 0.6261 - Recall: 0.1140 - accuracy: 0.3757 - loss: 1.7337 - mean_squared_error: 0.0752 - top_k_categorical_accuracy: 0.8658 - val_Precision: 0.7979 - val_Recall: 0.0683 - val_accuracy: 0.4142 - val_loss: 1.6706 - val_mean_squared_error: 0.0732 - val_top_k_categorical_accuracy: 0.8841\n",
      "Epoch 18/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6339 - Recall: 0.1193 - accuracy: 0.3746 - loss: 1.7198 - mean_squared_error: 0.0747 - top_k_categorical_accuracy: 0.8664 - val_Precision: 0.7841 - val_Recall: 0.0643 - val_accuracy: 0.4133 - val_loss: 1.6689 - val_mean_squared_error: 0.0733 - val_top_k_categorical_accuracy: 0.8867\n",
      "Epoch 19/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6198 - Recall: 0.1141 - accuracy: 0.3710 - loss: 1.7233 - mean_squared_error: 0.0751 - top_k_categorical_accuracy: 0.8671 - val_Precision: 0.7987 - val_Recall: 0.0607 - val_accuracy: 0.4223 - val_loss: 1.6746 - val_mean_squared_error: 0.0733 - val_top_k_categorical_accuracy: 0.8887\n",
      "Epoch 20/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6217 - Recall: 0.1166 - accuracy: 0.3743 - loss: 1.7250 - mean_squared_error: 0.0750 - top_k_categorical_accuracy: 0.8689 - val_Precision: 0.7721 - val_Recall: 0.0742 - val_accuracy: 0.4056 - val_loss: 1.6715 - val_mean_squared_error: 0.0733 - val_top_k_categorical_accuracy: 0.8839\n",
      "Epoch 21/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6292 - Recall: 0.1207 - accuracy: 0.3772 - loss: 1.7079 - mean_squared_error: 0.0746 - top_k_categorical_accuracy: 0.8731 - val_Precision: 0.7606 - val_Recall: 0.0718 - val_accuracy: 0.4075 - val_loss: 1.6729 - val_mean_squared_error: 0.0734 - val_top_k_categorical_accuracy: 0.8828\n",
      "Epoch 22/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6255 - Recall: 0.1235 - accuracy: 0.3819 - loss: 1.7036 - mean_squared_error: 0.0743 - top_k_categorical_accuracy: 0.8724 - val_Precision: 0.7492 - val_Recall: 0.0962 - val_accuracy: 0.4139 - val_loss: 1.6555 - val_mean_squared_error: 0.0725 - val_top_k_categorical_accuracy: 0.8873\n",
      "Epoch 23/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - Precision: 0.6272 - Recall: 0.1261 - accuracy: 0.3765 - loss: 1.7087 - mean_squared_error: 0.0745 - top_k_categorical_accuracy: 0.8709 - val_Precision: 0.7801 - val_Recall: 0.0809 - val_accuracy: 0.4222 - val_loss: 1.6307 - val_mean_squared_error: 0.0721 - val_top_k_categorical_accuracy: 0.8925\n",
      "Epoch 24/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6360 - Recall: 0.1263 - accuracy: 0.3820 - loss: 1.6968 - mean_squared_error: 0.0742 - top_k_categorical_accuracy: 0.8711 - val_Precision: 0.8067 - val_Recall: 0.0672 - val_accuracy: 0.4109 - val_loss: 1.6737 - val_mean_squared_error: 0.0732 - val_top_k_categorical_accuracy: 0.8819\n",
      "Epoch 25/25\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - Precision: 0.6389 - Recall: 0.1310 - accuracy: 0.3849 - loss: 1.6968 - mean_squared_error: 0.0740 - top_k_categorical_accuracy: 0.8730 - val_Precision: 0.7748 - val_Recall: 0.0812 - val_accuracy: 0.4144 - val_loss: 1.6668 - val_mean_squared_error: 0.0729 - val_top_k_categorical_accuracy: 0.8820\n",
      "Test loss: 1.6667855978012085\n",
      "Test accuracy: 0.41440001130104065\n",
      "Test precision: 0.7748091816902161\n",
      "Test recall: 0.0812000036239624\n",
      "Test top-K categorical accuracy: 0.8820000290870667\n",
      "Test mean squared error: 0.07286107540130615\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture for CIFAR-10\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', kernel_initializer=HeNormal(), input_shape=(3072,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu', kernel_initializer=HeNormal()),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu', kernel_initializer=HeNormal()),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy', 'mean_squared_error']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])\n",
    "print('Test mean squared error:', score[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d7c430-3633-44e0-b9d6-580958b651fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - Precision: 0.2310 - Recall: 0.0364 - accuracy: 0.1702 - loss: 2.7169 - mean_squared_error: 0.0960 - top_k_categorical_accuracy: 0.6485 - val_Precision: 0.5878 - val_Recall: 0.0763 - val_accuracy: 0.2987 - val_loss: 1.8835 - val_mean_squared_error: 0.0798 - val_top_k_categorical_accuracy: 0.8174\n",
      "Epoch 2/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.4845 - Recall: 0.0827 - accuracy: 0.2906 - loss: 1.9644 - mean_squared_error: 0.0823 - top_k_categorical_accuracy: 0.8014 - val_Precision: 0.5163 - val_Recall: 0.0698 - val_accuracy: 0.2934 - val_loss: 1.9488 - val_mean_squared_error: 0.0816 - val_top_k_categorical_accuracy: 0.8053\n",
      "Epoch 3/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.5529 - Recall: 0.1110 - accuracy: 0.3462 - loss: 1.8092 - mean_squared_error: 0.0777 - top_k_categorical_accuracy: 0.8483 - val_Precision: 0.5890 - val_Recall: 0.1148 - val_accuracy: 0.3336 - val_loss: 1.8428 - val_mean_squared_error: 0.0785 - val_top_k_categorical_accuracy: 0.8380\n",
      "Epoch 4/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.5868 - Recall: 0.1383 - accuracy: 0.3773 - loss: 1.7425 - mean_squared_error: 0.0753 - top_k_categorical_accuracy: 0.8645 - val_Precision: 0.6789 - val_Recall: 0.1554 - val_accuracy: 0.4054 - val_loss: 1.6539 - val_mean_squared_error: 0.0723 - val_top_k_categorical_accuracy: 0.8862\n",
      "Epoch 5/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6024 - Recall: 0.1631 - accuracy: 0.3960 - loss: 1.6892 - mean_squared_error: 0.0737 - top_k_categorical_accuracy: 0.8794 - val_Precision: 0.6191 - val_Recall: 0.1336 - val_accuracy: 0.3796 - val_loss: 1.7139 - val_mean_squared_error: 0.0751 - val_top_k_categorical_accuracy: 0.8776\n",
      "Epoch 6/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.6077 - Recall: 0.1761 - accuracy: 0.4068 - loss: 1.6586 - mean_squared_error: 0.0727 - top_k_categorical_accuracy: 0.8846 - val_Precision: 0.6835 - val_Recall: 0.1546 - val_accuracy: 0.4237 - val_loss: 1.6181 - val_mean_squared_error: 0.0711 - val_top_k_categorical_accuracy: 0.8889\n",
      "Epoch 7/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6208 - Recall: 0.1925 - accuracy: 0.4217 - loss: 1.6266 - mean_squared_error: 0.0716 - top_k_categorical_accuracy: 0.8879 - val_Precision: 0.6021 - val_Recall: 0.2394 - val_accuracy: 0.4334 - val_loss: 1.5550 - val_mean_squared_error: 0.0699 - val_top_k_categorical_accuracy: 0.9092\n",
      "Epoch 8/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.6289 - Recall: 0.2063 - accuracy: 0.4255 - loss: 1.6047 - mean_squared_error: 0.0708 - top_k_categorical_accuracy: 0.8942 - val_Precision: 0.6192 - val_Recall: 0.2327 - val_accuracy: 0.4511 - val_loss: 1.5663 - val_mean_squared_error: 0.0697 - val_top_k_categorical_accuracy: 0.9042\n",
      "Epoch 9/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6313 - Recall: 0.2159 - accuracy: 0.4354 - loss: 1.5879 - mean_squared_error: 0.0702 - top_k_categorical_accuracy: 0.8991 - val_Precision: 0.6726 - val_Recall: 0.2206 - val_accuracy: 0.4526 - val_loss: 1.5173 - val_mean_squared_error: 0.0680 - val_top_k_categorical_accuracy: 0.9117\n",
      "Epoch 10/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6425 - Recall: 0.2240 - accuracy: 0.4437 - loss: 1.5710 - mean_squared_error: 0.0695 - top_k_categorical_accuracy: 0.8990 - val_Precision: 0.6160 - val_Recall: 0.2416 - val_accuracy: 0.4228 - val_loss: 1.5793 - val_mean_squared_error: 0.0703 - val_top_k_categorical_accuracy: 0.8984\n",
      "Epoch 11/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Precision: 0.6482 - Recall: 0.2320 - accuracy: 0.4474 - loss: 1.5664 - mean_squared_error: 0.0691 - top_k_categorical_accuracy: 0.8990 - val_Precision: 0.7011 - val_Recall: 0.1717 - val_accuracy: 0.4394 - val_loss: 1.5919 - val_mean_squared_error: 0.0699 - val_top_k_categorical_accuracy: 0.8846\n",
      "Epoch 12/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - Precision: 0.6600 - Recall: 0.2397 - accuracy: 0.4509 - loss: 1.5488 - mean_squared_error: 0.0685 - top_k_categorical_accuracy: 0.9019 - val_Precision: 0.6380 - val_Recall: 0.2718 - val_accuracy: 0.4591 - val_loss: 1.5188 - val_mean_squared_error: 0.0678 - val_top_k_categorical_accuracy: 0.9058\n",
      "Epoch 13/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6582 - Recall: 0.2481 - accuracy: 0.4577 - loss: 1.5298 - mean_squared_error: 0.0679 - top_k_categorical_accuracy: 0.9071 - val_Precision: 0.6587 - val_Recall: 0.1731 - val_accuracy: 0.4149 - val_loss: 1.6059 - val_mean_squared_error: 0.0711 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 14/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6578 - Recall: 0.2504 - accuracy: 0.4607 - loss: 1.5208 - mean_squared_error: 0.0675 - top_k_categorical_accuracy: 0.9066 - val_Precision: 0.6550 - val_Recall: 0.2603 - val_accuracy: 0.4626 - val_loss: 1.4855 - val_mean_squared_error: 0.0670 - val_top_k_categorical_accuracy: 0.9141\n",
      "Epoch 15/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.6621 - Recall: 0.2567 - accuracy: 0.4631 - loss: 1.5149 - mean_squared_error: 0.0672 - top_k_categorical_accuracy: 0.9076 - val_Precision: 0.6453 - val_Recall: 0.2760 - val_accuracy: 0.4621 - val_loss: 1.5304 - val_mean_squared_error: 0.0677 - val_top_k_categorical_accuracy: 0.8968\n",
      "Epoch 16/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6672 - Recall: 0.2679 - accuracy: 0.4683 - loss: 1.4932 - mean_squared_error: 0.0664 - top_k_categorical_accuracy: 0.9111 - val_Precision: 0.6052 - val_Recall: 0.2676 - val_accuracy: 0.4440 - val_loss: 1.5293 - val_mean_squared_error: 0.0686 - val_top_k_categorical_accuracy: 0.9130\n",
      "Epoch 17/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Precision: 0.6684 - Recall: 0.2654 - accuracy: 0.4717 - loss: 1.4921 - mean_squared_error: 0.0664 - top_k_categorical_accuracy: 0.9112 - val_Precision: 0.7001 - val_Recall: 0.2418 - val_accuracy: 0.4868 - val_loss: 1.4508 - val_mean_squared_error: 0.0653 - val_top_k_categorical_accuracy: 0.9192\n",
      "Epoch 18/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6763 - Recall: 0.2805 - accuracy: 0.4795 - loss: 1.4782 - mean_squared_error: 0.0656 - top_k_categorical_accuracy: 0.9125 - val_Precision: 0.6649 - val_Recall: 0.2456 - val_accuracy: 0.4642 - val_loss: 1.5037 - val_mean_squared_error: 0.0673 - val_top_k_categorical_accuracy: 0.9127\n",
      "Epoch 19/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6708 - Recall: 0.2759 - accuracy: 0.4791 - loss: 1.4786 - mean_squared_error: 0.0658 - top_k_categorical_accuracy: 0.9131 - val_Precision: 0.6858 - val_Recall: 0.1862 - val_accuracy: 0.4229 - val_loss: 1.5667 - val_mean_squared_error: 0.0697 - val_top_k_categorical_accuracy: 0.9001\n",
      "Epoch 20/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6751 - Recall: 0.2765 - accuracy: 0.4778 - loss: 1.4801 - mean_squared_error: 0.0658 - top_k_categorical_accuracy: 0.9115 - val_Precision: 0.6894 - val_Recall: 0.2419 - val_accuracy: 0.4822 - val_loss: 1.4680 - val_mean_squared_error: 0.0659 - val_top_k_categorical_accuracy: 0.9137\n",
      "Epoch 21/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6767 - Recall: 0.2822 - accuracy: 0.4856 - loss: 1.4623 - mean_squared_error: 0.0651 - top_k_categorical_accuracy: 0.9163 - val_Precision: 0.7433 - val_Recall: 0.2311 - val_accuracy: 0.4868 - val_loss: 1.4311 - val_mean_squared_error: 0.0644 - val_top_k_categorical_accuracy: 0.9232\n",
      "Epoch 22/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.6790 - Recall: 0.2915 - accuracy: 0.4906 - loss: 1.4482 - mean_squared_error: 0.0646 - top_k_categorical_accuracy: 0.9163 - val_Precision: 0.6972 - val_Recall: 0.2733 - val_accuracy: 0.4974 - val_loss: 1.4118 - val_mean_squared_error: 0.0638 - val_top_k_categorical_accuracy: 0.9223\n",
      "Epoch 23/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.6849 - Recall: 0.2960 - accuracy: 0.4930 - loss: 1.4436 - mean_squared_error: 0.0643 - top_k_categorical_accuracy: 0.9163 - val_Precision: 0.6822 - val_Recall: 0.2745 - val_accuracy: 0.4783 - val_loss: 1.4693 - val_mean_squared_error: 0.0658 - val_top_k_categorical_accuracy: 0.9133\n",
      "Epoch 24/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6890 - Recall: 0.2940 - accuracy: 0.4909 - loss: 1.4460 - mean_squared_error: 0.0644 - top_k_categorical_accuracy: 0.9163 - val_Precision: 0.6604 - val_Recall: 0.2911 - val_accuracy: 0.4775 - val_loss: 1.4503 - val_mean_squared_error: 0.0653 - val_top_k_categorical_accuracy: 0.9163\n",
      "Epoch 25/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Precision: 0.6855 - Recall: 0.2960 - accuracy: 0.4931 - loss: 1.4438 - mean_squared_error: 0.0642 - top_k_categorical_accuracy: 0.9169 - val_Precision: 0.7347 - val_Recall: 0.2694 - val_accuracy: 0.5022 - val_loss: 1.4346 - val_mean_squared_error: 0.0637 - val_top_k_categorical_accuracy: 0.9117\n",
      "Epoch 26/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.6951 - Recall: 0.3012 - accuracy: 0.4966 - loss: 1.4348 - mean_squared_error: 0.0638 - top_k_categorical_accuracy: 0.9213 - val_Precision: 0.6777 - val_Recall: 0.2754 - val_accuracy: 0.4868 - val_loss: 1.4524 - val_mean_squared_error: 0.0653 - val_top_k_categorical_accuracy: 0.9261\n",
      "Epoch 27/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6906 - Recall: 0.3037 - accuracy: 0.4999 - loss: 1.4293 - mean_squared_error: 0.0637 - top_k_categorical_accuracy: 0.9193 - val_Precision: 0.7033 - val_Recall: 0.2697 - val_accuracy: 0.4925 - val_loss: 1.4517 - val_mean_squared_error: 0.0646 - val_top_k_categorical_accuracy: 0.9117\n",
      "Epoch 28/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7041 - Recall: 0.3088 - accuracy: 0.5016 - loss: 1.4223 - mean_squared_error: 0.0634 - top_k_categorical_accuracy: 0.9185 - val_Precision: 0.6484 - val_Recall: 0.2869 - val_accuracy: 0.4705 - val_loss: 1.4881 - val_mean_squared_error: 0.0666 - val_top_k_categorical_accuracy: 0.9155\n",
      "Epoch 29/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6992 - Recall: 0.3109 - accuracy: 0.5037 - loss: 1.4211 - mean_squared_error: 0.0633 - top_k_categorical_accuracy: 0.9191 - val_Precision: 0.6922 - val_Recall: 0.3227 - val_accuracy: 0.5107 - val_loss: 1.3911 - val_mean_squared_error: 0.0626 - val_top_k_categorical_accuracy: 0.9297\n",
      "Epoch 30/30\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6952 - Recall: 0.3154 - accuracy: 0.5084 - loss: 1.4112 - mean_squared_error: 0.0629 - top_k_categorical_accuracy: 0.9221 - val_Precision: 0.6987 - val_Recall: 0.2637 - val_accuracy: 0.4783 - val_loss: 1.4710 - val_mean_squared_error: 0.0654 - val_top_k_categorical_accuracy: 0.9106\n",
      "Test loss: 1.4709895849227905\n",
      "Test accuracy: 0.478300005197525\n",
      "Test precision: 0.6987281441688538\n",
      "Test recall: 0.263700008392334\n",
      "Test top-K categorical accuracy: 0.9106000065803528\n",
      "Test mean squared error: 0.06536535173654556\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture for CIFAR-10\n",
    "model = Sequential([\n",
    "    Dense(512, activation='elu', kernel_initializer=HeNormal(), input_shape=(3072,)),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(128, activation='elu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='RMSprop', \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy', 'mean_squared_error']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=30, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])\n",
    "print('Test mean squared error:', score[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f8bda14-b17c-4e9b-9889-15b1e42c588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:00:59.579159: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-28 16:00:59.676124: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 300 bytes spill stores, 276 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m385/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.3235 - Recall: 0.0119 - accuracy: 0.1966 - loss: 2.1994 - mean_squared_error: 0.0879 - top_k_categorical_accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:01:02.152560: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1426', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.174737: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.343679: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.343890: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1426', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.353723: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.484973: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1426', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.520864: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.579135: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1426_0', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.603125: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1442', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.604055: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 736 bytes spill stores, 752 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.606068: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1442', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.608408: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1442', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.642179: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1426', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.660122: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1426', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.693138: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1442', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.745111: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1442', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-10-28 16:01:02.848616: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1410', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - Precision: 0.3265 - Recall: 0.0122 - accuracy: 0.1974 - loss: 2.1978 - mean_squared_error: 0.0879 - top_k_categorical_accuracy: 0.6878 - val_Precision: 0.6535 - val_Recall: 0.0398 - val_accuracy: 0.3400 - val_loss: 1.8502 - val_mean_squared_error: 0.0790 - val_top_k_categorical_accuracy: 0.8416\n",
      "Epoch 2/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.5401 - Recall: 0.0525 - accuracy: 0.3088 - loss: 1.9093 - mean_squared_error: 0.0805 - top_k_categorical_accuracy: 0.8178 - val_Precision: 0.6611 - val_Recall: 0.0595 - val_accuracy: 0.3745 - val_loss: 1.7600 - val_mean_squared_error: 0.0762 - val_top_k_categorical_accuracy: 0.8665\n",
      "Epoch 3/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.5646 - Recall: 0.0754 - accuracy: 0.3432 - loss: 1.8296 - mean_squared_error: 0.0782 - top_k_categorical_accuracy: 0.8442 - val_Precision: 0.6905 - val_Recall: 0.0957 - val_accuracy: 0.4015 - val_loss: 1.6941 - val_mean_squared_error: 0.0739 - val_top_k_categorical_accuracy: 0.8805\n",
      "Epoch 4/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.5866 - Recall: 0.0989 - accuracy: 0.3637 - loss: 1.7726 - mean_squared_error: 0.0764 - top_k_categorical_accuracy: 0.8579 - val_Precision: 0.7227 - val_Recall: 0.0941 - val_accuracy: 0.4161 - val_loss: 1.6532 - val_mean_squared_error: 0.0727 - val_top_k_categorical_accuracy: 0.8918\n",
      "Epoch 5/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6022 - Recall: 0.1135 - accuracy: 0.3765 - loss: 1.7365 - mean_squared_error: 0.0753 - top_k_categorical_accuracy: 0.8672 - val_Precision: 0.7105 - val_Recall: 0.1004 - val_accuracy: 0.4313 - val_loss: 1.6154 - val_mean_squared_error: 0.0715 - val_top_k_categorical_accuracy: 0.9011\n",
      "Epoch 6/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6090 - Recall: 0.1225 - accuracy: 0.3879 - loss: 1.7143 - mean_squared_error: 0.0746 - top_k_categorical_accuracy: 0.8734 - val_Precision: 0.7008 - val_Recall: 0.1307 - val_accuracy: 0.4371 - val_loss: 1.5888 - val_mean_squared_error: 0.0706 - val_top_k_categorical_accuracy: 0.9042\n",
      "Epoch 7/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.6210 - Recall: 0.1404 - accuracy: 0.3957 - loss: 1.6776 - mean_squared_error: 0.0735 - top_k_categorical_accuracy: 0.8797 - val_Precision: 0.7082 - val_Recall: 0.1422 - val_accuracy: 0.4351 - val_loss: 1.5819 - val_mean_squared_error: 0.0703 - val_top_k_categorical_accuracy: 0.9036\n",
      "Epoch 8/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - Precision: 0.6261 - Recall: 0.1511 - accuracy: 0.4036 - loss: 1.6614 - mean_squared_error: 0.0729 - top_k_categorical_accuracy: 0.8838 - val_Precision: 0.7407 - val_Recall: 0.1388 - val_accuracy: 0.4591 - val_loss: 1.5471 - val_mean_squared_error: 0.0691 - val_top_k_categorical_accuracy: 0.9111\n",
      "Epoch 9/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.6377 - Recall: 0.1602 - accuracy: 0.4166 - loss: 1.6368 - mean_squared_error: 0.0720 - top_k_categorical_accuracy: 0.8868 - val_Precision: 0.7455 - val_Recall: 0.1535 - val_accuracy: 0.4615 - val_loss: 1.5258 - val_mean_squared_error: 0.0684 - val_top_k_categorical_accuracy: 0.9152\n",
      "Epoch 10/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.6474 - Recall: 0.1731 - accuracy: 0.4245 - loss: 1.6102 - mean_squared_error: 0.0711 - top_k_categorical_accuracy: 0.8929 - val_Precision: 0.7270 - val_Recall: 0.1720 - val_accuracy: 0.4604 - val_loss: 1.5272 - val_mean_squared_error: 0.0682 - val_top_k_categorical_accuracy: 0.9111\n",
      "Epoch 11/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6494 - Recall: 0.1815 - accuracy: 0.4291 - loss: 1.5950 - mean_squared_error: 0.0706 - top_k_categorical_accuracy: 0.8983 - val_Precision: 0.7582 - val_Recall: 0.1593 - val_accuracy: 0.4699 - val_loss: 1.5082 - val_mean_squared_error: 0.0676 - val_top_k_categorical_accuracy: 0.9134\n",
      "Epoch 12/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6494 - Recall: 0.1842 - accuracy: 0.4353 - loss: 1.5882 - mean_squared_error: 0.0703 - top_k_categorical_accuracy: 0.8963 - val_Precision: 0.7528 - val_Recall: 0.1422 - val_accuracy: 0.4671 - val_loss: 1.5277 - val_mean_squared_error: 0.0685 - val_top_k_categorical_accuracy: 0.9136\n",
      "Epoch 13/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - Precision: 0.6557 - Recall: 0.1941 - accuracy: 0.4355 - loss: 1.5697 - mean_squared_error: 0.0698 - top_k_categorical_accuracy: 0.9016 - val_Precision: 0.7474 - val_Recall: 0.1755 - val_accuracy: 0.4671 - val_loss: 1.5042 - val_mean_squared_error: 0.0674 - val_top_k_categorical_accuracy: 0.9131\n",
      "Epoch 14/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6572 - Recall: 0.2064 - accuracy: 0.4447 - loss: 1.5517 - mean_squared_error: 0.0691 - top_k_categorical_accuracy: 0.9055 - val_Precision: 0.7366 - val_Recall: 0.2002 - val_accuracy: 0.4820 - val_loss: 1.4683 - val_mean_squared_error: 0.0661 - val_top_k_categorical_accuracy: 0.9184\n",
      "Epoch 15/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.6676 - Recall: 0.2125 - accuracy: 0.4488 - loss: 1.5431 - mean_squared_error: 0.0687 - top_k_categorical_accuracy: 0.9048 - val_Precision: 0.7401 - val_Recall: 0.2016 - val_accuracy: 0.4843 - val_loss: 1.4553 - val_mean_squared_error: 0.0658 - val_top_k_categorical_accuracy: 0.9221\n",
      "Epoch 16/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6574 - Recall: 0.2107 - accuracy: 0.4498 - loss: 1.5344 - mean_squared_error: 0.0686 - top_k_categorical_accuracy: 0.9069 - val_Precision: 0.7295 - val_Recall: 0.2192 - val_accuracy: 0.4906 - val_loss: 1.4406 - val_mean_squared_error: 0.0652 - val_top_k_categorical_accuracy: 0.9249\n",
      "Epoch 17/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6644 - Recall: 0.2181 - accuracy: 0.4553 - loss: 1.5188 - mean_squared_error: 0.0681 - top_k_categorical_accuracy: 0.9121 - val_Precision: 0.7334 - val_Recall: 0.2135 - val_accuracy: 0.4826 - val_loss: 1.4484 - val_mean_squared_error: 0.0656 - val_top_k_categorical_accuracy: 0.9247\n",
      "Epoch 18/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.6708 - Recall: 0.2255 - accuracy: 0.4595 - loss: 1.5074 - mean_squared_error: 0.0675 - top_k_categorical_accuracy: 0.9116 - val_Precision: 0.7393 - val_Recall: 0.2212 - val_accuracy: 0.4887 - val_loss: 1.4349 - val_mean_squared_error: 0.0650 - val_top_k_categorical_accuracy: 0.9236\n",
      "Epoch 19/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.6736 - Recall: 0.2343 - accuracy: 0.4599 - loss: 1.5014 - mean_squared_error: 0.0673 - top_k_categorical_accuracy: 0.9104 - val_Precision: 0.7376 - val_Recall: 0.2521 - val_accuracy: 0.4985 - val_loss: 1.4119 - val_mean_squared_error: 0.0638 - val_top_k_categorical_accuracy: 0.9230\n",
      "Epoch 20/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6694 - Recall: 0.2388 - accuracy: 0.4701 - loss: 1.4879 - mean_squared_error: 0.0669 - top_k_categorical_accuracy: 0.9164 - val_Precision: 0.7533 - val_Recall: 0.2284 - val_accuracy: 0.4982 - val_loss: 1.4097 - val_mean_squared_error: 0.0640 - val_top_k_categorical_accuracy: 0.9264\n",
      "Epoch 21/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6771 - Recall: 0.2399 - accuracy: 0.4675 - loss: 1.4855 - mean_squared_error: 0.0667 - top_k_categorical_accuracy: 0.9128 - val_Precision: 0.7493 - val_Recall: 0.2478 - val_accuracy: 0.4981 - val_loss: 1.4040 - val_mean_squared_error: 0.0637 - val_top_k_categorical_accuracy: 0.9284\n",
      "Epoch 22/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6808 - Recall: 0.2491 - accuracy: 0.4762 - loss: 1.4642 - mean_squared_error: 0.0660 - top_k_categorical_accuracy: 0.9195 - val_Precision: 0.7390 - val_Recall: 0.2466 - val_accuracy: 0.5016 - val_loss: 1.4005 - val_mean_squared_error: 0.0636 - val_top_k_categorical_accuracy: 0.9279\n",
      "Epoch 23/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6790 - Recall: 0.2460 - accuracy: 0.4737 - loss: 1.4701 - mean_squared_error: 0.0662 - top_k_categorical_accuracy: 0.9187 - val_Precision: 0.7496 - val_Recall: 0.2482 - val_accuracy: 0.5059 - val_loss: 1.3923 - val_mean_squared_error: 0.0633 - val_top_k_categorical_accuracy: 0.9316\n",
      "Epoch 24/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - Precision: 0.6829 - Recall: 0.2573 - accuracy: 0.4796 - loss: 1.4576 - mean_squared_error: 0.0656 - top_k_categorical_accuracy: 0.9205 - val_Precision: 0.7431 - val_Recall: 0.2528 - val_accuracy: 0.5077 - val_loss: 1.3854 - val_mean_squared_error: 0.0630 - val_top_k_categorical_accuracy: 0.9276\n",
      "Epoch 25/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6810 - Recall: 0.2546 - accuracy: 0.4791 - loss: 1.4549 - mean_squared_error: 0.0657 - top_k_categorical_accuracy: 0.9207 - val_Precision: 0.7327 - val_Recall: 0.2653 - val_accuracy: 0.5042 - val_loss: 1.3865 - val_mean_squared_error: 0.0630 - val_top_k_categorical_accuracy: 0.9265\n",
      "Epoch 26/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6827 - Recall: 0.2644 - accuracy: 0.4856 - loss: 1.4360 - mean_squared_error: 0.0650 - top_k_categorical_accuracy: 0.9207 - val_Precision: 0.7502 - val_Recall: 0.2460 - val_accuracy: 0.5107 - val_loss: 1.3795 - val_mean_squared_error: 0.0628 - val_top_k_categorical_accuracy: 0.9305\n",
      "Epoch 27/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6834 - Recall: 0.2664 - accuracy: 0.4839 - loss: 1.4368 - mean_squared_error: 0.0650 - top_k_categorical_accuracy: 0.9215 - val_Precision: 0.7350 - val_Recall: 0.2868 - val_accuracy: 0.5144 - val_loss: 1.3578 - val_mean_squared_error: 0.0619 - val_top_k_categorical_accuracy: 0.9316\n",
      "Epoch 28/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6933 - Recall: 0.2788 - accuracy: 0.4929 - loss: 1.4152 - mean_squared_error: 0.0641 - top_k_categorical_accuracy: 0.9234 - val_Precision: 0.7493 - val_Recall: 0.2609 - val_accuracy: 0.5130 - val_loss: 1.3684 - val_mean_squared_error: 0.0625 - val_top_k_categorical_accuracy: 0.9311\n",
      "Epoch 29/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.6954 - Recall: 0.2772 - accuracy: 0.4928 - loss: 1.4092 - mean_squared_error: 0.0639 - top_k_categorical_accuracy: 0.9258 - val_Precision: 0.7281 - val_Recall: 0.2831 - val_accuracy: 0.5089 - val_loss: 1.3704 - val_mean_squared_error: 0.0623 - val_top_k_categorical_accuracy: 0.9310\n",
      "Epoch 30/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6874 - Recall: 0.2847 - accuracy: 0.4951 - loss: 1.4135 - mean_squared_error: 0.0642 - top_k_categorical_accuracy: 0.9258 - val_Precision: 0.7572 - val_Recall: 0.2782 - val_accuracy: 0.5237 - val_loss: 1.3488 - val_mean_squared_error: 0.0615 - val_top_k_categorical_accuracy: 0.9326\n",
      "Epoch 31/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.7004 - Recall: 0.2956 - accuracy: 0.5027 - loss: 1.3862 - mean_squared_error: 0.0631 - top_k_categorical_accuracy: 0.9279 - val_Precision: 0.7460 - val_Recall: 0.2840 - val_accuracy: 0.5253 - val_loss: 1.3374 - val_mean_squared_error: 0.0612 - val_top_k_categorical_accuracy: 0.9371\n",
      "Epoch 32/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.7001 - Recall: 0.2915 - accuracy: 0.5003 - loss: 1.3923 - mean_squared_error: 0.0633 - top_k_categorical_accuracy: 0.9286 - val_Precision: 0.7348 - val_Recall: 0.2907 - val_accuracy: 0.5258 - val_loss: 1.3418 - val_mean_squared_error: 0.0613 - val_top_k_categorical_accuracy: 0.9347\n",
      "Epoch 33/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - Precision: 0.6919 - Recall: 0.2911 - accuracy: 0.5026 - loss: 1.3914 - mean_squared_error: 0.0633 - top_k_categorical_accuracy: 0.9267 - val_Precision: 0.7268 - val_Recall: 0.3049 - val_accuracy: 0.5187 - val_loss: 1.3405 - val_mean_squared_error: 0.0613 - val_top_k_categorical_accuracy: 0.9340\n",
      "Epoch 34/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - Precision: 0.6952 - Recall: 0.2960 - accuracy: 0.5030 - loss: 1.3901 - mean_squared_error: 0.0632 - top_k_categorical_accuracy: 0.9290 - val_Precision: 0.7318 - val_Recall: 0.2897 - val_accuracy: 0.5182 - val_loss: 1.3512 - val_mean_squared_error: 0.0618 - val_top_k_categorical_accuracy: 0.9331\n",
      "Epoch 35/35\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.7001 - Recall: 0.3054 - accuracy: 0.5072 - loss: 1.3710 - mean_squared_error: 0.0624 - top_k_categorical_accuracy: 0.9302 - val_Precision: 0.7139 - val_Recall: 0.3012 - val_accuracy: 0.5200 - val_loss: 1.3471 - val_mean_squared_error: 0.0616 - val_top_k_categorical_accuracy: 0.9333\n",
      "Test loss: 1.3471121788024902\n",
      "Test accuracy: 0.5199999809265137\n",
      "Test precision: 0.7139132618904114\n",
      "Test recall: 0.3012000024318695\n",
      "Test top-K categorical accuracy: 0.9333000183105469\n",
      "Test mean squared error: 0.06156407296657562\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define the model architecture for CIFAR-10\n",
    "model = Sequential([\n",
    "    Dense(1024, kernel_initializer=HeNormal(), input_shape=(3072,)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.4),\n",
    "    Dense(512, kernel_initializer=HeNormal()),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, kernel_initializer=HeNormal()),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.4),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=SGD(learning_rate=0.01, momentum=0.9), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy', 'mean_squared_error']\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])\n",
    "print('Test mean squared error:', score[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c421e02c-99fa-4f39-9cb6-ed63e4cf08d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
