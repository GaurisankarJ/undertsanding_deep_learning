{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656393bd",
   "metadata": {},
   "source": [
    "### Step 1: Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5bca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3a407",
   "metadata": {},
   "source": [
    "### Step 2: Read training and test data from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c87c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1: Read training data from disk using pandas\n",
    "train_in = pd.read_csv(\"./resources/train_in.csv\")\n",
    "train_out = pd.read_csv(\"./resources/train_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e51d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2: Read test data from disk using pandas\n",
    "test_in = pd.read_csv(\"./resources/test_in.csv\")\n",
    "test_out = pd.read_csv(\"./resources/test_out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d256c",
   "metadata": {},
   "source": [
    "### Step 3: Transform data into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eac1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into matrix\n",
    "training_data_input = np.array(train_in)\n",
    "training_data_output = np.array(train_out)\n",
    "\n",
    "test_data_input = np.array(test_in)\n",
    "test_data_output = np.array(test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40204a",
   "metadata": {},
   "source": [
    "### Step 4: Initialise weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c809f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1: With zeros\n",
    "def initialise_weights_with_zeros(n_features, n_classes):\n",
    "    # (+ 1) is for the bias term\n",
    "    return np.zeros((n_features + 1, n_classes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069b2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2: With given number\n",
    "def initialise_weights_with_given_value(n_features, n_classes, value):\n",
    "    # (+ 1) is for the bias term\n",
    "    return np.full((n_features + 1, n_classes), value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc28f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3: With random values\n",
    "def initialise_weights_with_random_values(n_features, n_classes):\n",
    "    # (+ 1) is for the bias term\n",
    "    # (* 0.1) is used to keep the random numbers between -1 and 1, i.e. keep the values small\n",
    "    return np.random.randn(n_features + 1, n_classes) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70c8157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = training_data_input.shape[1]\n",
    "n_classes = len(set(training_data_output[:, 0]))\n",
    "\n",
    "w = initialise_weights_with_random_values(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14867494",
   "metadata": {},
   "source": [
    "### Step 5: Add bias to input matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f038762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_term(x):\n",
    "    # create a column with 1\n",
    "    bias = np.ones((x.shape[0], 1))\n",
    "    # append and return column with 1 to dataset\n",
    "    return np.hstack((x, bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce2643f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = add_bias_term(training_data_input)\n",
    "x_test = add_bias_term(test_data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28bcf65",
   "metadata": {},
   "source": [
    "### Step 6: Define perceptron algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575de2a",
   "metadata": {},
   "source": [
    "#### Basic Train Algorithm\n",
    "\n",
    "When a mistake is made (i.e., when the predicted class $\\hat{y}$ does not match the true class $y$), the weight vectors are updated as follows:\n",
    "\n",
    "- **Decrease** the weights for the wrongly predicted class $\\hat{y}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{\\hat{y}} = \\mathbf{w}_{\\hat{y}} - \\eta \\mathbf{x}\n",
    "$$\n",
    "\n",
    "- **Increase** the weights for the correct class $y$:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_y = \\mathbf{w}_y + \\eta \\mathbf{x}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate, which controls how much the weights are adjusted after each mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a79a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1: Basic train algorithm \n",
    "def perceptron_basic_train(w, x, learning_rate, i, increase = None, decrease = None):\n",
    "    if increase: \n",
    "        w[:, i] += learning_rate * x;\n",
    "    elif decrease:\n",
    "        w[:, i] -= learning_rate * x;\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7e1a7",
   "metadata": {},
   "source": [
    "#### Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83ee9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2: Gradient descent train algorithm \n",
    "def perceptron_gradient_descent_train(w, x, learning_rate, real_output):\n",
    "    # Dot product\n",
    "    scores = np.dot(x, w)\n",
    "    \n",
    "    # Softmax\n",
    "    probabilities = np.exp(scores) / np.sum(np.exp(scores))\n",
    "    \n",
    "    # Classes\n",
    "    n_classes = len(scores) \n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        indicator = 0\n",
    "        # Indicator function\n",
    "        if i + 1 == real_output:\n",
    "            indicator = 1\n",
    "        else:\n",
    "            indicator = 0\n",
    "        \n",
    "        gradient = (probabilities[i] - indicator) * x\n",
    "        \n",
    "        w[:, i] -= learning_rate * gradient\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c8c80",
   "metadata": {},
   "source": [
    "#### Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c27f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_predict(x, w):\n",
    "    # compute dot product\n",
    "    scores = np.dot(x, w)\n",
    "    # return max value of scores matrix\n",
    "    return np.argmax(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d277f",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384b0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(right_prediction, wrong_prediction):\n",
    "    return right_prediction / (right_prediction + wrong_prediction) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d1e22",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ff5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron training: Basic\n",
    "def perceptron_training_basic(w, training_data_input, training_data_output, learning_rate, training_algorithm):\n",
    "    right_prediction = 0\n",
    "    wrong_prediction = 0\n",
    "    \n",
    "    for index, row in enumerate(training_data_input):\n",
    "        real_output = training_data_output[index, :][0]\n",
    "        prediction_index = perceptron_predict(row, w)\n",
    "\n",
    "        if real_output == prediction_index + 1:\n",
    "            training_algorithm(w, row, learning_rate, prediction_index, increase = True)\n",
    "            right_prediction += 1;\n",
    "        else:\n",
    "            training_algorithm(w, row, learning_rate, prediction_index, decrease = True)\n",
    "            wrong_prediction += 1;\n",
    "    \n",
    "    accuracy = calculate_accuracy(right_prediction, wrong_prediction)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65dbc544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron training: Gradient Descent\n",
    "def perceptron_training_gradient_descent(w, training_data_input, training_data_output, learning_rate, training_algorithm):\n",
    "    right_prediction = 0\n",
    "    wrong_prediction = 0\n",
    "    \n",
    "    for index, row in enumerate(training_data_input):\n",
    "        real_output = training_data_output[index, :][0]\n",
    "        prediction_index = perceptron_predict(row, w)\n",
    "        \n",
    "        training_algorithm(w, row, learning_rate, real_output)\n",
    "        \n",
    "        if real_output == prediction_index + 1:\n",
    "            right_prediction += 1;\n",
    "        else:\n",
    "            wrong_prediction += 1;\n",
    "    \n",
    "    accuracy = calculate_accuracy(right_prediction, wrong_prediction)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f59ae3",
   "metadata": {},
   "source": [
    "#### Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b981b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "def run_n_epochs(n_epochs, learning_rate):\n",
    "    accuracy = 0\n",
    "    for i in range(n_epochs):\n",
    "         # Change train algorithm\n",
    "        acc = perceptron_training_basic(w, x_train, training_data_output, learning_rate, perceptron_basic_train)\n",
    "        accuracy = acc;\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1923df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "def run_n_epochs(n_epochs, learning_rate):\n",
    "    accuracy = 0\n",
    "    for i in range(n_epochs):\n",
    "         # Change train algorithm\n",
    "        acc = perceptron_training_gradient_descent(w, x_train, training_data_output, learning_rate, perceptron_gradient_descent_train)\n",
    "        accuracy = acc;\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92a9a6",
   "metadata": {},
   "source": [
    "### 7: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d253b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 14.77%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = run_n_epochs(100, 0.01)\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2dd35b",
   "metadata": {},
   "source": [
    "### 8: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7fe8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_test(w, testing_data_input, testing_data_output):\n",
    "    right_prediction = 0\n",
    "    wrong_prediction = 0\n",
    "    \n",
    "    for index, row in enumerate(testing_data_input):\n",
    "        real_output = testing_data_output[index, :][0]\n",
    "        prediction_index = perceptron_predict(row, w)\n",
    "\n",
    "        if real_output == prediction_index + 1:\n",
    "            right_prediction += 1;\n",
    "        else:\n",
    "            wrong_prediction += 1;\n",
    "    \n",
    "    accuracy = calculate_accuracy(right_prediction, wrong_prediction)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c05117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 41.64%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = perceptron_test(w, x_test, test_data_output)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70959333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60108d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb842a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb969f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cbea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = training_data_input.shape[1]\n",
    "n_classes = len(set(training_data_output[:, 0]))\n",
    "\n",
    "w = initialise_weights_with_random_values(n_features, n_classes)\n",
    "training_data_input = add_bias_term(training_data_input)\n",
    "\n",
    "perceptron_training(w, training_data_input, training_data_output, 0.001, perceptron_basic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa214ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc339ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in range(2000):\n",
    "    a = perceptron_training(w, training_data_input, training_data_output, 0.01, perceptron_basic_train)\n",
    "    acc = a;\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224855dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full((1, 8), 1.0)\n",
    "w = np.full((8, 10), 2.0)\n",
    "\n",
    "print(x)\n",
    "print(w)\n",
    "basic_training(w,x, 0.5, 2, increase = True)\n",
    "# w[:, 2] += x[0, :];\n",
    "print(x)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dfab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perceptron_predict(np.full((2, 3), 1), np.full((3, 2), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588cd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, 10)\n",
    "print(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full((1, 8), 1)\n",
    "w = np.full((8, 10), 2)\n",
    "d = np.dot(x, w)\n",
    "m = np.argmax(d, axis=1)\n",
    "print(x, w, d)\n",
    "print(m)\n",
    "\n",
    "q = [[16, 16, 16, 16, 16, 16, 21, 16, 16, 16]]\n",
    "m = np.argmax(q)\n",
    "print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
