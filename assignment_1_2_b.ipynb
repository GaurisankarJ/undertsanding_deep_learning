{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b19c4eb-9d51-4072-9908-8fa53b5d410b",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59a4031a-4d74-48e7-a450-e50f9b9b4b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Load Fashion MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Reshape based on channels ordering\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed5173-4c49-42ee-8bcc-eb9748c3a00d",
   "metadata": {},
   "source": [
    "## 1: Simple CNN\n",
    "A basic CNN with two convolutional layers and max-pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ace51f3-7b1d-4653-880a-ec97976330cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Precision: 0.8242 - Recall: 0.5916 - accuracy: 0.7072 - loss: 0.8193 - top_k_categorical_accuracy: 0.9710 - val_Precision: 0.8804 - val_Recall: 0.8178 - val_accuracy: 0.8477 - val_loss: 0.3993 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 2/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8873 - Recall: 0.8080 - accuracy: 0.8475 - loss: 0.4156 - top_k_categorical_accuracy: 0.9970 - val_Precision: 0.8878 - val_Recall: 0.8345 - val_accuracy: 0.8597 - val_loss: 0.3622 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 3/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9005 - Recall: 0.8382 - accuracy: 0.8702 - loss: 0.3588 - top_k_categorical_accuracy: 0.9978 - val_Precision: 0.9095 - val_Recall: 0.8695 - val_accuracy: 0.8875 - val_loss: 0.3059 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 4/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9074 - Recall: 0.8574 - accuracy: 0.8839 - loss: 0.3233 - top_k_categorical_accuracy: 0.9984 - val_Precision: 0.9137 - val_Recall: 0.8790 - val_accuracy: 0.8942 - val_loss: 0.2939 - val_top_k_categorical_accuracy: 0.9983\n",
      "Epoch 5/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9159 - Recall: 0.8733 - accuracy: 0.8948 - loss: 0.2916 - top_k_categorical_accuracy: 0.9985 - val_Precision: 0.9139 - val_Recall: 0.8870 - val_accuracy: 0.8976 - val_loss: 0.2804 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 6/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9213 - Recall: 0.8832 - accuracy: 0.9034 - loss: 0.2693 - top_k_categorical_accuracy: 0.9988 - val_Precision: 0.9169 - val_Recall: 0.8899 - val_accuracy: 0.9006 - val_loss: 0.2673 - val_top_k_categorical_accuracy: 0.9991\n",
      "Epoch 7/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9263 - Recall: 0.8903 - accuracy: 0.9086 - loss: 0.2533 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9201 - val_Recall: 0.8977 - val_accuracy: 0.9084 - val_loss: 0.2535 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 8/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9274 - Recall: 0.8947 - accuracy: 0.9106 - loss: 0.2439 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9218 - val_Recall: 0.8949 - val_accuracy: 0.9074 - val_loss: 0.2565 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 9/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9295 - Recall: 0.8986 - accuracy: 0.9135 - loss: 0.2349 - top_k_categorical_accuracy: 0.9993 - val_Precision: 0.9185 - val_Recall: 0.8975 - val_accuracy: 0.9063 - val_loss: 0.2527 - val_top_k_categorical_accuracy: 0.9987\n",
      "Epoch 10/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9344 - Recall: 0.9065 - accuracy: 0.9189 - loss: 0.2159 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9217 - val_Recall: 0.9035 - val_accuracy: 0.9115 - val_loss: 0.2423 - val_top_k_categorical_accuracy: 0.9987\n",
      "Epoch 11/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9373 - Recall: 0.9112 - accuracy: 0.9236 - loss: 0.2062 - top_k_categorical_accuracy: 0.9995 - val_Precision: 0.9186 - val_Recall: 0.9022 - val_accuracy: 0.9088 - val_loss: 0.2530 - val_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 12/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9396 - Recall: 0.9172 - accuracy: 0.9277 - loss: 0.1986 - top_k_categorical_accuracy: 0.9997 - val_Precision: 0.9223 - val_Recall: 0.9035 - val_accuracy: 0.9110 - val_loss: 0.2470 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 13/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9389 - Recall: 0.9165 - accuracy: 0.9273 - loss: 0.1928 - top_k_categorical_accuracy: 0.9998 - val_Precision: 0.9265 - val_Recall: 0.9031 - val_accuracy: 0.9122 - val_loss: 0.2442 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 14/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9411 - Recall: 0.9190 - accuracy: 0.9299 - loss: 0.1841 - top_k_categorical_accuracy: 0.9996 - val_Precision: 0.9231 - val_Recall: 0.9089 - val_accuracy: 0.9140 - val_loss: 0.2534 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 15/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9435 - Recall: 0.9221 - accuracy: 0.9325 - loss: 0.1796 - top_k_categorical_accuracy: 0.9998 - val_Precision: 0.9231 - val_Recall: 0.9070 - val_accuracy: 0.9142 - val_loss: 0.2508 - val_top_k_categorical_accuracy: 0.9991\n",
      "Epoch 16/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9467 - Recall: 0.9296 - accuracy: 0.9378 - loss: 0.1648 - top_k_categorical_accuracy: 0.9998 - val_Precision: 0.9219 - val_Recall: 0.9074 - val_accuracy: 0.9133 - val_loss: 0.2577 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 17/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9461 - Recall: 0.9303 - accuracy: 0.9381 - loss: 0.1631 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9241 - val_Recall: 0.9113 - val_accuracy: 0.9169 - val_loss: 0.2511 - val_top_k_categorical_accuracy: 0.9992\n",
      "Epoch 18/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9464 - Recall: 0.9311 - accuracy: 0.9387 - loss: 0.1614 - top_k_categorical_accuracy: 0.9998 - val_Precision: 0.9188 - val_Recall: 0.9063 - val_accuracy: 0.9103 - val_loss: 0.2658 - val_top_k_categorical_accuracy: 0.9991\n",
      "Epoch 19/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9488 - Recall: 0.9328 - accuracy: 0.9403 - loss: 0.1538 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9240 - val_Recall: 0.9129 - val_accuracy: 0.9179 - val_loss: 0.2560 - val_top_k_categorical_accuracy: 0.9992\n",
      "Epoch 20/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9515 - Recall: 0.9371 - accuracy: 0.9440 - loss: 0.1461 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9192 - val_Recall: 0.9104 - val_accuracy: 0.9140 - val_loss: 0.2744 - val_top_k_categorical_accuracy: 0.9992\n",
      "Epoch 21/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9523 - Recall: 0.9378 - accuracy: 0.9451 - loss: 0.1436 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9205 - val_Recall: 0.9111 - val_accuracy: 0.9146 - val_loss: 0.2728 - val_top_k_categorical_accuracy: 0.9991\n",
      "Epoch 22/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9517 - Recall: 0.9386 - accuracy: 0.9452 - loss: 0.1406 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9228 - val_Recall: 0.9121 - val_accuracy: 0.9167 - val_loss: 0.2775 - val_top_k_categorical_accuracy: 0.9992\n",
      "Epoch 23/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9557 - Recall: 0.9436 - accuracy: 0.9496 - loss: 0.1329 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9234 - val_Recall: 0.9111 - val_accuracy: 0.9153 - val_loss: 0.2836 - val_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 24/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9572 - Recall: 0.9442 - accuracy: 0.9509 - loss: 0.1310 - top_k_categorical_accuracy: 1.0000 - val_Precision: 0.9233 - val_Recall: 0.9143 - val_accuracy: 0.9175 - val_loss: 0.2699 - val_top_k_categorical_accuracy: 0.9987\n",
      "Epoch 25/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9568 - Recall: 0.9460 - accuracy: 0.9515 - loss: 0.1238 - top_k_categorical_accuracy: 1.0000 - val_Precision: 0.9173 - val_Recall: 0.9098 - val_accuracy: 0.9122 - val_loss: 0.3080 - val_top_k_categorical_accuracy: 0.9992\n",
      "Epoch 26/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9587 - Recall: 0.9480 - accuracy: 0.9533 - loss: 0.1193 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9230 - val_Recall: 0.9127 - val_accuracy: 0.9167 - val_loss: 0.2921 - val_top_k_categorical_accuracy: 0.9992\n",
      "Epoch 27/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9596 - Recall: 0.9491 - accuracy: 0.9544 - loss: 0.1174 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9210 - val_Recall: 0.9129 - val_accuracy: 0.9160 - val_loss: 0.3052 - val_top_k_categorical_accuracy: 0.9986\n",
      "Epoch 28/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9572 - Recall: 0.9463 - accuracy: 0.9515 - loss: 0.1214 - top_k_categorical_accuracy: 1.0000 - val_Precision: 0.9215 - val_Recall: 0.9128 - val_accuracy: 0.9157 - val_loss: 0.2971 - val_top_k_categorical_accuracy: 0.9989\n",
      "Epoch 29/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9620 - Recall: 0.9528 - accuracy: 0.9576 - loss: 0.1107 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9219 - val_Recall: 0.9138 - val_accuracy: 0.9171 - val_loss: 0.2899 - val_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 30/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9600 - Recall: 0.9508 - accuracy: 0.9552 - loss: 0.1146 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9193 - val_Recall: 0.9138 - val_accuracy: 0.9155 - val_loss: 0.3094 - val_top_k_categorical_accuracy: 0.9991\n",
      "Epoch 31/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9620 - Recall: 0.9540 - accuracy: 0.9578 - loss: 0.1057 - top_k_categorical_accuracy: 1.0000 - val_Precision: 0.9195 - val_Recall: 0.9099 - val_accuracy: 0.9142 - val_loss: 0.3132 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 32/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9628 - Recall: 0.9542 - accuracy: 0.9585 - loss: 0.1046 - top_k_categorical_accuracy: 1.0000 - val_Precision: 0.9221 - val_Recall: 0.9168 - val_accuracy: 0.9187 - val_loss: 0.3376 - val_top_k_categorical_accuracy: 0.9988\n",
      "Epoch 33/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9638 - Recall: 0.9571 - accuracy: 0.9603 - loss: 0.1009 - top_k_categorical_accuracy: 1.0000 - val_Precision: 0.9196 - val_Recall: 0.9123 - val_accuracy: 0.9150 - val_loss: 0.3293 - val_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 34/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9649 - Recall: 0.9570 - accuracy: 0.9607 - loss: 0.0999 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9200 - val_Recall: 0.9143 - val_accuracy: 0.9159 - val_loss: 0.3384 - val_top_k_categorical_accuracy: 0.9986\n",
      "Epoch 35/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9660 - Recall: 0.9585 - accuracy: 0.9620 - loss: 0.0934 - top_k_categorical_accuracy: 0.9999 - val_Precision: 0.9188 - val_Recall: 0.9125 - val_accuracy: 0.9156 - val_loss: 0.3565 - val_top_k_categorical_accuracy: 0.9988\n",
      "Test loss: 0.35647255182266235\n",
      "Test accuracy: 0.9156000018119812\n",
      "Test precision: 0.9188399910926819\n",
      "Test recall: 0.9125000238418579\n",
      "Test top-K categorical accuracy: 0.9987999796867371\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c65c418-5c85-41e8-94c3-ad1061b4fb01",
   "metadata": {},
   "source": [
    "## 2: Moderate CNN with Batch Normalization\n",
    "A slightly deeper CNN that includes batch normalisation to improve stability during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28cb3dbe-2e23-4ef2-ba88-3cfb1a2ffcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - Precision: 0.8369 - Recall: 0.7345 - accuracy: 0.7820 - loss: 0.6215 - top_k_categorical_accuracy: 0.9830 - val_Precision: 0.8815 - val_Recall: 0.8435 - val_accuracy: 0.8607 - val_loss: 0.3938 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 2/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9031 - Recall: 0.8637 - accuracy: 0.8820 - loss: 0.3330 - top_k_categorical_accuracy: 0.9977 - val_Precision: 0.9017 - val_Recall: 0.8723 - val_accuracy: 0.8855 - val_loss: 0.3387 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 3/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9145 - Recall: 0.8804 - accuracy: 0.8969 - loss: 0.2975 - top_k_categorical_accuracy: 0.9980 - val_Precision: 0.8978 - val_Recall: 0.8799 - val_accuracy: 0.8881 - val_loss: 0.3739 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 4/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9208 - Recall: 0.8894 - accuracy: 0.9050 - loss: 0.2801 - top_k_categorical_accuracy: 0.9986 - val_Precision: 0.9031 - val_Recall: 0.8828 - val_accuracy: 0.8905 - val_loss: 0.3875 - val_top_k_categorical_accuracy: 0.9972\n",
      "Epoch 5/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9237 - Recall: 0.8887 - accuracy: 0.9067 - loss: 0.2735 - top_k_categorical_accuracy: 0.9986 - val_Precision: 0.9014 - val_Recall: 0.8816 - val_accuracy: 0.8897 - val_loss: 0.4123 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 6/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9267 - Recall: 0.8935 - accuracy: 0.9098 - loss: 0.2661 - top_k_categorical_accuracy: 0.9987 - val_Precision: 0.9179 - val_Recall: 0.8810 - val_accuracy: 0.8991 - val_loss: 0.3556 - val_top_k_categorical_accuracy: 0.9974\n",
      "Epoch 7/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9288 - Recall: 0.8967 - accuracy: 0.9136 - loss: 0.2621 - top_k_categorical_accuracy: 0.9989 - val_Precision: 0.8774 - val_Recall: 0.8267 - val_accuracy: 0.8514 - val_loss: 0.4219 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 8/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9307 - Recall: 0.8998 - accuracy: 0.9149 - loss: 0.2520 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.8921 - val_Recall: 0.8642 - val_accuracy: 0.8776 - val_loss: 0.4551 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 9/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9345 - Recall: 0.9025 - accuracy: 0.9183 - loss: 0.2525 - top_k_categorical_accuracy: 0.9989 - val_Precision: 0.9077 - val_Recall: 0.8630 - val_accuracy: 0.8870 - val_loss: 0.3890 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 10/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9336 - Recall: 0.9027 - accuracy: 0.9187 - loss: 0.2482 - top_k_categorical_accuracy: 0.9988 - val_Precision: 0.8601 - val_Recall: 0.8525 - val_accuracy: 0.8556 - val_loss: 0.9332 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 11/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9371 - Recall: 0.9075 - accuracy: 0.9229 - loss: 0.2356 - top_k_categorical_accuracy: 0.9992 - val_Precision: 0.9045 - val_Recall: 0.8782 - val_accuracy: 0.8907 - val_loss: 0.4039 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 12/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9375 - Recall: 0.9069 - accuracy: 0.9219 - loss: 0.2315 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9036 - val_Recall: 0.8891 - val_accuracy: 0.8956 - val_loss: 0.4257 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 13/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9392 - Recall: 0.9108 - accuracy: 0.9246 - loss: 0.2244 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9141 - val_Recall: 0.8750 - val_accuracy: 0.8952 - val_loss: 0.3537 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 14/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9419 - Recall: 0.9161 - accuracy: 0.9295 - loss: 0.2158 - top_k_categorical_accuracy: 0.9993 - val_Precision: 0.9120 - val_Recall: 0.8959 - val_accuracy: 0.9023 - val_loss: 0.4118 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 15/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9428 - Recall: 0.9176 - accuracy: 0.9302 - loss: 0.2114 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9121 - val_Recall: 0.8589 - val_accuracy: 0.8891 - val_loss: 0.3507 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 16/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9437 - Recall: 0.9160 - accuracy: 0.9295 - loss: 0.2138 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9054 - val_Recall: 0.8921 - val_accuracy: 0.8975 - val_loss: 0.4952 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 17/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9439 - Recall: 0.9194 - accuracy: 0.9316 - loss: 0.2104 - top_k_categorical_accuracy: 0.9990 - val_Precision: 0.9222 - val_Recall: 0.8521 - val_accuracy: 0.8917 - val_loss: 0.4036 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 18/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9447 - Recall: 0.9183 - accuracy: 0.9326 - loss: 0.2035 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9158 - val_Recall: 0.8837 - val_accuracy: 0.9010 - val_loss: 0.3858 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 19/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9453 - Recall: 0.9211 - accuracy: 0.9335 - loss: 0.2008 - top_k_categorical_accuracy: 0.9993 - val_Precision: 0.9158 - val_Recall: 0.9012 - val_accuracy: 0.9081 - val_loss: 0.3768 - val_top_k_categorical_accuracy: 0.9984\n",
      "Epoch 20/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9480 - Recall: 0.9251 - accuracy: 0.9361 - loss: 0.1893 - top_k_categorical_accuracy: 0.9991 - val_Precision: 0.9035 - val_Recall: 0.8917 - val_accuracy: 0.8968 - val_loss: 0.5221 - val_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 21/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.9485 - Recall: 0.9266 - accuracy: 0.9375 - loss: 0.1890 - top_k_categorical_accuracy: 0.9995 - val_Precision: 0.9197 - val_Recall: 0.8836 - val_accuracy: 0.9015 - val_loss: 0.3487 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 22/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - Precision: 0.9495 - Recall: 0.9289 - accuracy: 0.9397 - loss: 0.1758 - top_k_categorical_accuracy: 0.9995 - val_Precision: 0.9022 - val_Recall: 0.8879 - val_accuracy: 0.8935 - val_loss: 0.4671 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 23/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9513 - Recall: 0.9315 - accuracy: 0.9416 - loss: 0.1748 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9129 - val_Recall: 0.8911 - val_accuracy: 0.9034 - val_loss: 0.3980 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 24/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9506 - Recall: 0.9304 - accuracy: 0.9409 - loss: 0.1742 - top_k_categorical_accuracy: 0.9993 - val_Precision: 0.9128 - val_Recall: 0.8344 - val_accuracy: 0.8798 - val_loss: 0.4187 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 25/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9543 - Recall: 0.9352 - accuracy: 0.9449 - loss: 0.1659 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9060 - val_Recall: 0.8941 - val_accuracy: 0.9000 - val_loss: 0.4333 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 26/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9559 - Recall: 0.9373 - accuracy: 0.9472 - loss: 0.1599 - top_k_categorical_accuracy: 0.9995 - val_Precision: 0.9087 - val_Recall: 0.8945 - val_accuracy: 0.9003 - val_loss: 0.4339 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 27/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9566 - Recall: 0.9387 - accuracy: 0.9476 - loss: 0.1576 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9066 - val_Recall: 0.8794 - val_accuracy: 0.8916 - val_loss: 0.4672 - val_top_k_categorical_accuracy: 0.9969\n",
      "Epoch 28/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9565 - Recall: 0.9390 - accuracy: 0.9477 - loss: 0.1574 - top_k_categorical_accuracy: 0.9997 - val_Precision: 0.9029 - val_Recall: 0.8996 - val_accuracy: 0.9012 - val_loss: 0.7557 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 29/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9571 - Recall: 0.9405 - accuracy: 0.9485 - loss: 0.1585 - top_k_categorical_accuracy: 0.9995 - val_Precision: 0.8891 - val_Recall: 0.8819 - val_accuracy: 0.8850 - val_loss: 0.6523 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 30/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9579 - Recall: 0.9429 - accuracy: 0.9501 - loss: 0.1516 - top_k_categorical_accuracy: 0.9993 - val_Precision: 0.9074 - val_Recall: 0.8930 - val_accuracy: 0.8990 - val_loss: 0.4825 - val_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 31/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9594 - Recall: 0.9447 - accuracy: 0.9523 - loss: 0.1444 - top_k_categorical_accuracy: 0.9996 - val_Precision: 0.9140 - val_Recall: 0.8964 - val_accuracy: 0.9045 - val_loss: 0.4085 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 32/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9605 - Recall: 0.9444 - accuracy: 0.9525 - loss: 0.1420 - top_k_categorical_accuracy: 0.9994 - val_Precision: 0.9043 - val_Recall: 0.8893 - val_accuracy: 0.8958 - val_loss: 0.4740 - val_top_k_categorical_accuracy: 0.9978\n",
      "Epoch 33/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9617 - Recall: 0.9487 - accuracy: 0.9549 - loss: 0.1326 - top_k_categorical_accuracy: 0.9998 - val_Precision: 0.9078 - val_Recall: 0.8850 - val_accuracy: 0.8974 - val_loss: 0.4382 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 34/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9627 - Recall: 0.9499 - accuracy: 0.9565 - loss: 0.1352 - top_k_categorical_accuracy: 0.9995 - val_Precision: 0.8916 - val_Recall: 0.8763 - val_accuracy: 0.8846 - val_loss: 0.5626 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 35/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9633 - Recall: 0.9497 - accuracy: 0.9559 - loss: 0.1319 - top_k_categorical_accuracy: 0.9995 - val_Precision: 0.9092 - val_Recall: 0.8881 - val_accuracy: 0.8983 - val_loss: 0.4612 - val_top_k_categorical_accuracy: 0.9976\n",
      "Test loss: 0.46122831106185913\n",
      "Test accuracy: 0.8982999920845032\n",
      "Test precision: 0.9091932773590088\n",
      "Test recall: 0.8881000280380249\n",
      "Test top-K categorical accuracy: 0.9976000189781189\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=RMSprop(learning_rate=0.001), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1b28c-0c23-4253-828d-5ebf82c48bdf",
   "metadata": {},
   "source": [
    "## 3: Deeper CNN with Leaky ReLU and Regularization\n",
    "A more complex CNN with Leaky ReLU activations and L2 regularisation to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d052223-6650-4f8f-bcb0-0eab31428125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4374886/.conda/envs/idl1/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - Precision: 0.5828 - Recall: 0.1369 - accuracy: 0.3529 - loss: 2.8754 - top_k_categorical_accuracy: 0.7986 - val_Precision: 0.8313 - val_Recall: 0.5522 - val_accuracy: 0.6948 - val_loss: 1.8982 - val_top_k_categorical_accuracy: 0.9876\n",
      "Epoch 2/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8142 - Recall: 0.5656 - accuracy: 0.6863 - loss: 1.8854 - top_k_categorical_accuracy: 0.9891 - val_Precision: 0.8787 - val_Recall: 0.5988 - val_accuracy: 0.7344 - val_loss: 1.7371 - val_top_k_categorical_accuracy: 0.9923\n",
      "Epoch 3/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8419 - Recall: 0.6260 - accuracy: 0.7323 - loss: 1.7265 - top_k_categorical_accuracy: 0.9922 - val_Precision: 0.8580 - val_Recall: 0.6446 - val_accuracy: 0.7547 - val_loss: 1.6489 - val_top_k_categorical_accuracy: 0.9936\n",
      "Epoch 4/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8500 - Recall: 0.6634 - accuracy: 0.7589 - loss: 1.6302 - top_k_categorical_accuracy: 0.9937 - val_Precision: 0.8908 - val_Recall: 0.6675 - val_accuracy: 0.7825 - val_loss: 1.5510 - val_top_k_categorical_accuracy: 0.9956\n",
      "Epoch 5/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8581 - Recall: 0.6911 - accuracy: 0.7750 - loss: 1.5550 - top_k_categorical_accuracy: 0.9940 - val_Precision: 0.8725 - val_Recall: 0.7098 - val_accuracy: 0.7892 - val_loss: 1.4922 - val_top_k_categorical_accuracy: 0.9957\n",
      "Epoch 6/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8614 - Recall: 0.7061 - accuracy: 0.7837 - loss: 1.4942 - top_k_categorical_accuracy: 0.9955 - val_Precision: 0.8735 - val_Recall: 0.7220 - val_accuracy: 0.7984 - val_loss: 1.4317 - val_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 7/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8656 - Recall: 0.7206 - accuracy: 0.7929 - loss: 1.4369 - top_k_categorical_accuracy: 0.9955 - val_Precision: 0.8653 - val_Recall: 0.7463 - val_accuracy: 0.8044 - val_loss: 1.3815 - val_top_k_categorical_accuracy: 0.9967\n",
      "Epoch 8/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8686 - Recall: 0.7372 - accuracy: 0.8036 - loss: 1.3840 - top_k_categorical_accuracy: 0.9960 - val_Precision: 0.8836 - val_Recall: 0.7449 - val_accuracy: 0.8179 - val_loss: 1.3354 - val_top_k_categorical_accuracy: 0.9969\n",
      "Epoch 9/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8688 - Recall: 0.7466 - accuracy: 0.8112 - loss: 1.3418 - top_k_categorical_accuracy: 0.9956 - val_Precision: 0.8780 - val_Recall: 0.7646 - val_accuracy: 0.8250 - val_loss: 1.2856 - val_top_k_categorical_accuracy: 0.9973\n",
      "Epoch 10/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8714 - Recall: 0.7544 - accuracy: 0.8155 - loss: 1.3016 - top_k_categorical_accuracy: 0.9964 - val_Precision: 0.8747 - val_Recall: 0.7756 - val_accuracy: 0.8253 - val_loss: 1.2500 - val_top_k_categorical_accuracy: 0.9976\n",
      "Epoch 11/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8738 - Recall: 0.7642 - accuracy: 0.8194 - loss: 1.2599 - top_k_categorical_accuracy: 0.9960 - val_Precision: 0.8844 - val_Recall: 0.7787 - val_accuracy: 0.8341 - val_loss: 1.2111 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 12/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8775 - Recall: 0.7739 - accuracy: 0.8270 - loss: 1.2173 - top_k_categorical_accuracy: 0.9971 - val_Precision: 0.8795 - val_Recall: 0.7947 - val_accuracy: 0.8369 - val_loss: 1.1728 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 13/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8773 - Recall: 0.7826 - accuracy: 0.8314 - loss: 1.1817 - top_k_categorical_accuracy: 0.9970 - val_Precision: 0.8845 - val_Recall: 0.7957 - val_accuracy: 0.8416 - val_loss: 1.1459 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 14/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8821 - Recall: 0.7926 - accuracy: 0.8380 - loss: 1.1429 - top_k_categorical_accuracy: 0.9973 - val_Precision: 0.8896 - val_Recall: 0.8014 - val_accuracy: 0.8461 - val_loss: 1.1117 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 15/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8828 - Recall: 0.7946 - accuracy: 0.8396 - loss: 1.1157 - top_k_categorical_accuracy: 0.9972 - val_Precision: 0.8887 - val_Recall: 0.8012 - val_accuracy: 0.8474 - val_loss: 1.0850 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 16/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8825 - Recall: 0.7983 - accuracy: 0.8415 - loss: 1.0889 - top_k_categorical_accuracy: 0.9968 - val_Precision: 0.8898 - val_Recall: 0.8156 - val_accuracy: 0.8540 - val_loss: 1.0449 - val_top_k_categorical_accuracy: 0.9977\n",
      "Epoch 17/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8837 - Recall: 0.8057 - accuracy: 0.8440 - loss: 1.0542 - top_k_categorical_accuracy: 0.9976 - val_Precision: 0.8893 - val_Recall: 0.8184 - val_accuracy: 0.8543 - val_loss: 1.0203 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 18/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8877 - Recall: 0.8100 - accuracy: 0.8503 - loss: 1.0272 - top_k_categorical_accuracy: 0.9976 - val_Precision: 0.8896 - val_Recall: 0.8224 - val_accuracy: 0.8566 - val_loss: 0.9963 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 19/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8864 - Recall: 0.8095 - accuracy: 0.8474 - loss: 1.0060 - top_k_categorical_accuracy: 0.9973 - val_Precision: 0.8905 - val_Recall: 0.8273 - val_accuracy: 0.8593 - val_loss: 0.9695 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 20/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8897 - Recall: 0.8185 - accuracy: 0.8538 - loss: 0.9736 - top_k_categorical_accuracy: 0.9977 - val_Precision: 0.8936 - val_Recall: 0.8305 - val_accuracy: 0.8612 - val_loss: 0.9466 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 21/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8884 - Recall: 0.8169 - accuracy: 0.8528 - loss: 0.9605 - top_k_categorical_accuracy: 0.9974 - val_Precision: 0.8978 - val_Recall: 0.8275 - val_accuracy: 0.8607 - val_loss: 0.9283 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 22/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8906 - Recall: 0.8202 - accuracy: 0.8549 - loss: 0.9344 - top_k_categorical_accuracy: 0.9977 - val_Precision: 0.8917 - val_Recall: 0.8285 - val_accuracy: 0.8586 - val_loss: 0.9114 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 23/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8925 - Recall: 0.8260 - accuracy: 0.8601 - loss: 0.9068 - top_k_categorical_accuracy: 0.9979 - val_Precision: 0.8976 - val_Recall: 0.8346 - val_accuracy: 0.8656 - val_loss: 0.8817 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 24/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8927 - Recall: 0.8292 - accuracy: 0.8605 - loss: 0.8871 - top_k_categorical_accuracy: 0.9979 - val_Precision: 0.8980 - val_Recall: 0.8387 - val_accuracy: 0.8671 - val_loss: 0.8576 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 25/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8946 - Recall: 0.8306 - accuracy: 0.8645 - loss: 0.8671 - top_k_categorical_accuracy: 0.9979 - val_Precision: 0.8966 - val_Recall: 0.8388 - val_accuracy: 0.8680 - val_loss: 0.8428 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 26/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8941 - Recall: 0.8328 - accuracy: 0.8628 - loss: 0.8459 - top_k_categorical_accuracy: 0.9978 - val_Precision: 0.8998 - val_Recall: 0.8442 - val_accuracy: 0.8694 - val_loss: 0.8209 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 27/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8944 - Recall: 0.8345 - accuracy: 0.8641 - loss: 0.8333 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.8999 - val_Recall: 0.8486 - val_accuracy: 0.8707 - val_loss: 0.8029 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 28/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8950 - Recall: 0.8386 - accuracy: 0.8663 - loss: 0.8087 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.8993 - val_Recall: 0.8447 - val_accuracy: 0.8694 - val_loss: 0.7918 - val_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 29/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8979 - Recall: 0.8390 - accuracy: 0.8674 - loss: 0.7930 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.8990 - val_Recall: 0.8497 - val_accuracy: 0.8729 - val_loss: 0.7727 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 30/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8950 - Recall: 0.8424 - accuracy: 0.8686 - loss: 0.7736 - top_k_categorical_accuracy: 0.9982 - val_Precision: 0.9033 - val_Recall: 0.8491 - val_accuracy: 0.8741 - val_loss: 0.7561 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 31/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8990 - Recall: 0.8447 - accuracy: 0.8719 - loss: 0.7606 - top_k_categorical_accuracy: 0.9979 - val_Precision: 0.9033 - val_Recall: 0.8543 - val_accuracy: 0.8768 - val_loss: 0.7378 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 32/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8972 - Recall: 0.8417 - accuracy: 0.8681 - loss: 0.7500 - top_k_categorical_accuracy: 0.9983 - val_Precision: 0.9032 - val_Recall: 0.8570 - val_accuracy: 0.8789 - val_loss: 0.7216 - val_top_k_categorical_accuracy: 0.9983\n",
      "Epoch 33/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9029 - Recall: 0.8516 - accuracy: 0.8774 - loss: 0.7262 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.9037 - val_Recall: 0.8547 - val_accuracy: 0.8766 - val_loss: 0.7099 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 34/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9015 - Recall: 0.8479 - accuracy: 0.8760 - loss: 0.7161 - top_k_categorical_accuracy: 0.9981 - val_Precision: 0.9028 - val_Recall: 0.8568 - val_accuracy: 0.8767 - val_loss: 0.6949 - val_top_k_categorical_accuracy: 0.9981\n",
      "Epoch 35/35\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.9019 - Recall: 0.8513 - accuracy: 0.8761 - loss: 0.7012 - top_k_categorical_accuracy: 0.9980 - val_Precision: 0.9056 - val_Recall: 0.8603 - val_accuracy: 0.8802 - val_loss: 0.6844 - val_top_k_categorical_accuracy: 0.9982\n",
      "Test loss: 0.6844098567962646\n",
      "Test accuracy: 0.8802000284194946\n",
      "Test precision: 0.9055789709091187\n",
      "Test recall: 0.8603000044822693\n",
      "Test top-K categorical accuracy: 0.998199999332428\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), kernel_regularizer=l2(0.001), input_shape=(28, 28, 1)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(128, (3, 3), kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(256, (3, 3), kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Flatten(),\n",
    "    Dense(512, kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=SGD(learning_rate=0.001, momentum=0.9), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e61704-116e-4ba9-8fd8-b83f9cb12741",
   "metadata": {},
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "639845f7-40af-4bce-9801-7ca10c5ebbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "channels = 3\n",
    "\n",
    "# Load CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Reshape based on channels ordering\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n",
    "    input_shape = (channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee1899b2-5513-4454-a7de-78c3737c6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Precision: 0.5222 - Recall: 0.0609 - accuracy: 0.3066 - loss: 1.8767 - top_k_categorical_accuracy: 0.8072 - val_Precision: 0.7262 - val_Recall: 0.2382 - val_accuracy: 0.4896 - val_loss: 1.4176 - val_top_k_categorical_accuracy: 0.9226\n",
      "Epoch 2/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.6824 - Recall: 0.2396 - accuracy: 0.4817 - loss: 1.4270 - top_k_categorical_accuracy: 0.9288 - val_Precision: 0.8053 - val_Recall: 0.3264 - val_accuracy: 0.5857 - val_loss: 1.1925 - val_top_k_categorical_accuracy: 0.9538\n",
      "Epoch 3/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.7277 - Recall: 0.3376 - accuracy: 0.5495 - loss: 1.2629 - top_k_categorical_accuracy: 0.9467 - val_Precision: 0.7962 - val_Recall: 0.4215 - val_accuracy: 0.6238 - val_loss: 1.0801 - val_top_k_categorical_accuracy: 0.9630\n",
      "Epoch 4/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7509 - Recall: 0.4019 - accuracy: 0.5834 - loss: 1.1625 - top_k_categorical_accuracy: 0.9567 - val_Precision: 0.7848 - val_Recall: 0.4632 - val_accuracy: 0.6330 - val_loss: 1.0296 - val_top_k_categorical_accuracy: 0.9657\n",
      "Epoch 5/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7684 - Recall: 0.4514 - accuracy: 0.6169 - loss: 1.0895 - top_k_categorical_accuracy: 0.9613 - val_Precision: 0.8056 - val_Recall: 0.4939 - val_accuracy: 0.6584 - val_loss: 0.9734 - val_top_k_categorical_accuracy: 0.9697\n",
      "Epoch 6/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.7771 - Recall: 0.4839 - accuracy: 0.6384 - loss: 1.0298 - top_k_categorical_accuracy: 0.9663 - val_Precision: 0.8038 - val_Recall: 0.5211 - val_accuracy: 0.6607 - val_loss: 0.9570 - val_top_k_categorical_accuracy: 0.9690\n",
      "Epoch 7/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7922 - Recall: 0.5101 - accuracy: 0.6572 - loss: 0.9815 - top_k_categorical_accuracy: 0.9693 - val_Precision: 0.8044 - val_Recall: 0.5431 - val_accuracy: 0.6751 - val_loss: 0.9168 - val_top_k_categorical_accuracy: 0.9702\n",
      "Epoch 8/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.7988 - Recall: 0.5383 - accuracy: 0.6740 - loss: 0.9329 - top_k_categorical_accuracy: 0.9738 - val_Precision: 0.8134 - val_Recall: 0.5674 - val_accuracy: 0.6900 - val_loss: 0.8805 - val_top_k_categorical_accuracy: 0.9730\n",
      "Epoch 9/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8048 - Recall: 0.5520 - accuracy: 0.6799 - loss: 0.9061 - top_k_categorical_accuracy: 0.9758 - val_Precision: 0.7951 - val_Recall: 0.5809 - val_accuracy: 0.6869 - val_loss: 0.8869 - val_top_k_categorical_accuracy: 0.9727\n",
      "Epoch 10/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8144 - Recall: 0.5794 - accuracy: 0.6947 - loss: 0.8558 - top_k_categorical_accuracy: 0.9792 - val_Precision: 0.8034 - val_Recall: 0.5953 - val_accuracy: 0.6967 - val_loss: 0.8614 - val_top_k_categorical_accuracy: 0.9763\n",
      "Epoch 11/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8163 - Recall: 0.5958 - accuracy: 0.7081 - loss: 0.8264 - top_k_categorical_accuracy: 0.9810 - val_Precision: 0.8076 - val_Recall: 0.6045 - val_accuracy: 0.7026 - val_loss: 0.8440 - val_top_k_categorical_accuracy: 0.9754\n",
      "Epoch 12/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8211 - Recall: 0.6062 - accuracy: 0.7130 - loss: 0.8058 - top_k_categorical_accuracy: 0.9802 - val_Precision: 0.8137 - val_Recall: 0.6088 - val_accuracy: 0.7082 - val_loss: 0.8360 - val_top_k_categorical_accuracy: 0.9748\n",
      "Epoch 13/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8280 - Recall: 0.6149 - accuracy: 0.7230 - loss: 0.7841 - top_k_categorical_accuracy: 0.9828 - val_Precision: 0.8040 - val_Recall: 0.6068 - val_accuracy: 0.7000 - val_loss: 0.8668 - val_top_k_categorical_accuracy: 0.9716\n",
      "Epoch 14/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8273 - Recall: 0.6295 - accuracy: 0.7295 - loss: 0.7548 - top_k_categorical_accuracy: 0.9837 - val_Precision: 0.8054 - val_Recall: 0.6157 - val_accuracy: 0.7129 - val_loss: 0.8392 - val_top_k_categorical_accuracy: 0.9766\n",
      "Epoch 15/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8304 - Recall: 0.6392 - accuracy: 0.7372 - loss: 0.7357 - top_k_categorical_accuracy: 0.9857 - val_Precision: 0.7965 - val_Recall: 0.6286 - val_accuracy: 0.7094 - val_loss: 0.8477 - val_top_k_categorical_accuracy: 0.9744\n",
      "Epoch 16/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8371 - Recall: 0.6497 - accuracy: 0.7458 - loss: 0.7152 - top_k_categorical_accuracy: 0.9865 - val_Precision: 0.7912 - val_Recall: 0.6256 - val_accuracy: 0.7067 - val_loss: 0.8620 - val_top_k_categorical_accuracy: 0.9728\n",
      "Epoch 17/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8452 - Recall: 0.6603 - accuracy: 0.7522 - loss: 0.6991 - top_k_categorical_accuracy: 0.9873 - val_Precision: 0.7983 - val_Recall: 0.6415 - val_accuracy: 0.7159 - val_loss: 0.8340 - val_top_k_categorical_accuracy: 0.9760\n",
      "Epoch 18/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8377 - Recall: 0.6671 - accuracy: 0.7530 - loss: 0.6817 - top_k_categorical_accuracy: 0.9888 - val_Precision: 0.7901 - val_Recall: 0.6504 - val_accuracy: 0.7139 - val_loss: 0.8590 - val_top_k_categorical_accuracy: 0.9744\n",
      "Epoch 19/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8431 - Recall: 0.6757 - accuracy: 0.7573 - loss: 0.6698 - top_k_categorical_accuracy: 0.9881 - val_Precision: 0.7825 - val_Recall: 0.6310 - val_accuracy: 0.6986 - val_loss: 0.9074 - val_top_k_categorical_accuracy: 0.9718\n",
      "Epoch 20/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8441 - Recall: 0.6770 - accuracy: 0.7616 - loss: 0.6577 - top_k_categorical_accuracy: 0.9888 - val_Precision: 0.7951 - val_Recall: 0.6555 - val_accuracy: 0.7174 - val_loss: 0.8496 - val_top_k_categorical_accuracy: 0.9765\n",
      "Epoch 21/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8432 - Recall: 0.6782 - accuracy: 0.7621 - loss: 0.6512 - top_k_categorical_accuracy: 0.9892 - val_Precision: 0.7912 - val_Recall: 0.6407 - val_accuracy: 0.7154 - val_loss: 0.8700 - val_top_k_categorical_accuracy: 0.9753\n",
      "Epoch 22/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8525 - Recall: 0.6987 - accuracy: 0.7758 - loss: 0.6173 - top_k_categorical_accuracy: 0.9917 - val_Precision: 0.7887 - val_Recall: 0.6557 - val_accuracy: 0.7157 - val_loss: 0.8608 - val_top_k_categorical_accuracy: 0.9751\n",
      "Epoch 23/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8536 - Recall: 0.7064 - accuracy: 0.7783 - loss: 0.6025 - top_k_categorical_accuracy: 0.9915 - val_Precision: 0.7905 - val_Recall: 0.6547 - val_accuracy: 0.7180 - val_loss: 0.8670 - val_top_k_categorical_accuracy: 0.9755\n",
      "Epoch 24/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8590 - Recall: 0.7148 - accuracy: 0.7860 - loss: 0.5838 - top_k_categorical_accuracy: 0.9920 - val_Precision: 0.7870 - val_Recall: 0.6579 - val_accuracy: 0.7163 - val_loss: 0.8724 - val_top_k_categorical_accuracy: 0.9749\n",
      "Epoch 25/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Precision: 0.8574 - Recall: 0.7105 - accuracy: 0.7829 - loss: 0.5969 - top_k_categorical_accuracy: 0.9922 - val_Precision: 0.7874 - val_Recall: 0.6629 - val_accuracy: 0.7213 - val_loss: 0.8802 - val_top_k_categorical_accuracy: 0.9768\n",
      "Epoch 26/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8573 - Recall: 0.7172 - accuracy: 0.7867 - loss: 0.5833 - top_k_categorical_accuracy: 0.9918 - val_Precision: 0.7825 - val_Recall: 0.6678 - val_accuracy: 0.7148 - val_loss: 0.9059 - val_top_k_categorical_accuracy: 0.9739\n",
      "Epoch 27/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8574 - Recall: 0.7209 - accuracy: 0.7869 - loss: 0.5720 - top_k_categorical_accuracy: 0.9927 - val_Precision: 0.7696 - val_Recall: 0.6577 - val_accuracy: 0.7082 - val_loss: 0.9440 - val_top_k_categorical_accuracy: 0.9740\n",
      "Epoch 28/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8660 - Recall: 0.7334 - accuracy: 0.7952 - loss: 0.5509 - top_k_categorical_accuracy: 0.9935 - val_Precision: 0.7701 - val_Recall: 0.6541 - val_accuracy: 0.7058 - val_loss: 0.9609 - val_top_k_categorical_accuracy: 0.9720\n",
      "Epoch 29/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8620 - Recall: 0.7314 - accuracy: 0.7956 - loss: 0.5521 - top_k_categorical_accuracy: 0.9934 - val_Precision: 0.7714 - val_Recall: 0.6717 - val_accuracy: 0.7150 - val_loss: 0.9278 - val_top_k_categorical_accuracy: 0.9724\n",
      "Epoch 30/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8603 - Recall: 0.7330 - accuracy: 0.7950 - loss: 0.5516 - top_k_categorical_accuracy: 0.9931 - val_Precision: 0.7751 - val_Recall: 0.6736 - val_accuracy: 0.7178 - val_loss: 0.9349 - val_top_k_categorical_accuracy: 0.9736\n",
      "Epoch 31/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8645 - Recall: 0.7432 - accuracy: 0.8035 - loss: 0.5299 - top_k_categorical_accuracy: 0.9945 - val_Precision: 0.7736 - val_Recall: 0.6811 - val_accuracy: 0.7204 - val_loss: 0.9534 - val_top_k_categorical_accuracy: 0.9736\n",
      "Epoch 32/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8659 - Recall: 0.7480 - accuracy: 0.8046 - loss: 0.5187 - top_k_categorical_accuracy: 0.9946 - val_Precision: 0.7619 - val_Recall: 0.6723 - val_accuracy: 0.7091 - val_loss: 0.9959 - val_top_k_categorical_accuracy: 0.9728\n",
      "Epoch 33/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8672 - Recall: 0.7493 - accuracy: 0.8055 - loss: 0.5235 - top_k_categorical_accuracy: 0.9948 - val_Precision: 0.7716 - val_Recall: 0.6743 - val_accuracy: 0.7168 - val_loss: 0.9615 - val_top_k_categorical_accuracy: 0.9747\n",
      "Epoch 34/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8680 - Recall: 0.7518 - accuracy: 0.8065 - loss: 0.5097 - top_k_categorical_accuracy: 0.9949 - val_Precision: 0.7777 - val_Recall: 0.6781 - val_accuracy: 0.7231 - val_loss: 0.9524 - val_top_k_categorical_accuracy: 0.9745\n",
      "Epoch 35/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8697 - Recall: 0.7541 - accuracy: 0.8102 - loss: 0.5029 - top_k_categorical_accuracy: 0.9945 - val_Precision: 0.7718 - val_Recall: 0.6723 - val_accuracy: 0.7151 - val_loss: 0.9684 - val_top_k_categorical_accuracy: 0.9730\n",
      "Test loss: 0.968430757522583\n",
      "Test accuracy: 0.7150999903678894\n",
      "Test precision: 0.7717828154563904\n",
      "Test recall: 0.6722999811172485\n",
      "Test top-K categorical accuracy: 0.9729999899864197\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model architecture for CIFAR-10\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef79af73-5d75-4030-97ed-663637505d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - Precision: 0.5857 - Recall: 0.2177 - accuracy: 0.4094 - loss: 1.7197 - top_k_categorical_accuracy: 0.8638 - val_Precision: 0.6069 - val_Recall: 0.4224 - val_accuracy: 0.5138 - val_loss: 1.5068 - val_top_k_categorical_accuracy: 0.9294\n",
      "Epoch 2/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.7456 - Recall: 0.4868 - accuracy: 0.6157 - loss: 1.1214 - top_k_categorical_accuracy: 0.9555 - val_Precision: 0.7420 - val_Recall: 0.5352 - val_accuracy: 0.6389 - val_loss: 1.0568 - val_top_k_categorical_accuracy: 0.9648\n",
      "Epoch 3/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.7812 - Recall: 0.5660 - accuracy: 0.6722 - loss: 0.9624 - top_k_categorical_accuracy: 0.9680 - val_Precision: 0.6812 - val_Recall: 0.5504 - val_accuracy: 0.6121 - val_loss: 1.2718 - val_top_k_categorical_accuracy: 0.9538\n",
      "Epoch 4/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8011 - Recall: 0.6017 - accuracy: 0.6985 - loss: 0.8855 - top_k_categorical_accuracy: 0.9748 - val_Precision: 0.6421 - val_Recall: 0.5142 - val_accuracy: 0.5769 - val_loss: 1.4979 - val_top_k_categorical_accuracy: 0.9512\n",
      "Epoch 5/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8183 - Recall: 0.6260 - accuracy: 0.7210 - loss: 0.8464 - top_k_categorical_accuracy: 0.9759 - val_Precision: 0.4513 - val_Recall: 0.4204 - val_accuracy: 0.4365 - val_loss: 3.4001 - val_top_k_categorical_accuracy: 0.9202\n",
      "Epoch 6/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8215 - Recall: 0.6342 - accuracy: 0.7244 - loss: 0.8376 - top_k_categorical_accuracy: 0.9767 - val_Precision: 0.7305 - val_Recall: 0.5278 - val_accuracy: 0.6255 - val_loss: 1.2723 - val_top_k_categorical_accuracy: 0.9529\n",
      "Epoch 7/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8299 - Recall: 0.6485 - accuracy: 0.7379 - loss: 0.8127 - top_k_categorical_accuracy: 0.9767 - val_Precision: 0.5428 - val_Recall: 0.4663 - val_accuracy: 0.5017 - val_loss: 2.7293 - val_top_k_categorical_accuracy: 0.9062\n",
      "Epoch 8/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8329 - Recall: 0.6464 - accuracy: 0.7378 - loss: 0.8140 - top_k_categorical_accuracy: 0.9779 - val_Precision: 0.7656 - val_Recall: 0.5712 - val_accuracy: 0.6671 - val_loss: 1.1354 - val_top_k_categorical_accuracy: 0.9592\n",
      "Epoch 9/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8352 - Recall: 0.6619 - accuracy: 0.7471 - loss: 0.7957 - top_k_categorical_accuracy: 0.9775 - val_Precision: 0.5074 - val_Recall: 0.4599 - val_accuracy: 0.4794 - val_loss: 4.5107 - val_top_k_categorical_accuracy: 0.8780\n",
      "Epoch 10/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8372 - Recall: 0.6605 - accuracy: 0.7475 - loss: 0.7898 - top_k_categorical_accuracy: 0.9794 - val_Precision: 0.7563 - val_Recall: 0.5125 - val_accuracy: 0.6216 - val_loss: 1.2232 - val_top_k_categorical_accuracy: 0.9450\n",
      "Epoch 11/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8453 - Recall: 0.6749 - accuracy: 0.7552 - loss: 0.7626 - top_k_categorical_accuracy: 0.9791 - val_Precision: 0.7744 - val_Recall: 0.4006 - val_accuracy: 0.5840 - val_loss: 1.2832 - val_top_k_categorical_accuracy: 0.9432\n",
      "Epoch 12/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8488 - Recall: 0.6764 - accuracy: 0.7581 - loss: 0.7568 - top_k_categorical_accuracy: 0.9801 - val_Precision: 0.7425 - val_Recall: 0.5786 - val_accuracy: 0.6474 - val_loss: 1.2475 - val_top_k_categorical_accuracy: 0.9469\n",
      "Epoch 13/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8499 - Recall: 0.6878 - accuracy: 0.7662 - loss: 0.7381 - top_k_categorical_accuracy: 0.9823 - val_Precision: 0.6272 - val_Recall: 0.5350 - val_accuracy: 0.5778 - val_loss: 2.0040 - val_top_k_categorical_accuracy: 0.9317\n",
      "Epoch 14/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8541 - Recall: 0.6966 - accuracy: 0.7708 - loss: 0.7158 - top_k_categorical_accuracy: 0.9814 - val_Precision: 0.6793 - val_Recall: 0.5961 - val_accuracy: 0.6301 - val_loss: 1.7134 - val_top_k_categorical_accuracy: 0.9557\n",
      "Epoch 15/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8549 - Recall: 0.6931 - accuracy: 0.7719 - loss: 0.7125 - top_k_categorical_accuracy: 0.9821 - val_Precision: 0.7588 - val_Recall: 0.5901 - val_accuracy: 0.6769 - val_loss: 1.2133 - val_top_k_categorical_accuracy: 0.9670\n",
      "Epoch 16/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8570 - Recall: 0.6997 - accuracy: 0.7754 - loss: 0.7119 - top_k_categorical_accuracy: 0.9811 - val_Precision: 0.6695 - val_Recall: 0.5691 - val_accuracy: 0.6128 - val_loss: 1.8509 - val_top_k_categorical_accuracy: 0.9382\n",
      "Epoch 17/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8578 - Recall: 0.7087 - accuracy: 0.7811 - loss: 0.6920 - top_k_categorical_accuracy: 0.9819 - val_Precision: 0.6958 - val_Recall: 0.6476 - val_accuracy: 0.6674 - val_loss: 1.6603 - val_top_k_categorical_accuracy: 0.9683\n",
      "Epoch 18/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8579 - Recall: 0.7084 - accuracy: 0.7798 - loss: 0.6963 - top_k_categorical_accuracy: 0.9817 - val_Precision: 0.7643 - val_Recall: 0.6561 - val_accuracy: 0.7048 - val_loss: 1.1751 - val_top_k_categorical_accuracy: 0.9710\n",
      "Epoch 19/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8613 - Recall: 0.7135 - accuracy: 0.7841 - loss: 0.6819 - top_k_categorical_accuracy: 0.9830 - val_Precision: 0.7349 - val_Recall: 0.5554 - val_accuracy: 0.6431 - val_loss: 1.1737 - val_top_k_categorical_accuracy: 0.9628\n",
      "Epoch 20/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8670 - Recall: 0.7182 - accuracy: 0.7893 - loss: 0.6726 - top_k_categorical_accuracy: 0.9829 - val_Precision: 0.6761 - val_Recall: 0.5886 - val_accuracy: 0.6227 - val_loss: 1.8194 - val_top_k_categorical_accuracy: 0.9551\n",
      "Epoch 21/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8680 - Recall: 0.7280 - accuracy: 0.7951 - loss: 0.6517 - top_k_categorical_accuracy: 0.9826 - val_Precision: 0.7129 - val_Recall: 0.5272 - val_accuracy: 0.6204 - val_loss: 1.4467 - val_top_k_categorical_accuracy: 0.9521\n",
      "Epoch 22/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8688 - Recall: 0.7222 - accuracy: 0.7933 - loss: 0.6510 - top_k_categorical_accuracy: 0.9839 - val_Precision: 0.6437 - val_Recall: 0.5618 - val_accuracy: 0.5973 - val_loss: 2.2702 - val_top_k_categorical_accuracy: 0.9330\n",
      "Epoch 23/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8705 - Recall: 0.7294 - accuracy: 0.7964 - loss: 0.6487 - top_k_categorical_accuracy: 0.9821 - val_Precision: 0.6632 - val_Recall: 0.5610 - val_accuracy: 0.6065 - val_loss: 1.8718 - val_top_k_categorical_accuracy: 0.9547\n",
      "Epoch 24/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8663 - Recall: 0.7246 - accuracy: 0.7955 - loss: 0.6624 - top_k_categorical_accuracy: 0.9836 - val_Precision: 0.6801 - val_Recall: 0.6312 - val_accuracy: 0.6517 - val_loss: 2.1015 - val_top_k_categorical_accuracy: 0.9520\n",
      "Epoch 25/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8711 - Recall: 0.7277 - accuracy: 0.7979 - loss: 0.6467 - top_k_categorical_accuracy: 0.9841 - val_Precision: 0.7423 - val_Recall: 0.6663 - val_accuracy: 0.6966 - val_loss: 1.4342 - val_top_k_categorical_accuracy: 0.9603\n",
      "Epoch 26/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8733 - Recall: 0.7352 - accuracy: 0.8034 - loss: 0.6345 - top_k_categorical_accuracy: 0.9854 - val_Precision: 0.7733 - val_Recall: 0.5699 - val_accuracy: 0.6693 - val_loss: 1.1501 - val_top_k_categorical_accuracy: 0.9636\n",
      "Epoch 27/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8701 - Recall: 0.7317 - accuracy: 0.7993 - loss: 0.6462 - top_k_categorical_accuracy: 0.9838 - val_Precision: 0.8770 - val_Recall: 0.3816 - val_accuracy: 0.6241 - val_loss: 1.1980 - val_top_k_categorical_accuracy: 0.9350\n",
      "Epoch 28/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8747 - Recall: 0.7399 - accuracy: 0.8047 - loss: 0.6224 - top_k_categorical_accuracy: 0.9854 - val_Precision: 0.7558 - val_Recall: 0.6441 - val_accuracy: 0.6897 - val_loss: 1.2781 - val_top_k_categorical_accuracy: 0.9637\n",
      "Epoch 29/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - Precision: 0.8755 - Recall: 0.7409 - accuracy: 0.8053 - loss: 0.6296 - top_k_categorical_accuracy: 0.9842 - val_Precision: 0.7471 - val_Recall: 0.6217 - val_accuracy: 0.6830 - val_loss: 1.3376 - val_top_k_categorical_accuracy: 0.9663\n",
      "Epoch 30/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8746 - Recall: 0.7415 - accuracy: 0.8074 - loss: 0.6368 - top_k_categorical_accuracy: 0.9852 - val_Precision: 0.7026 - val_Recall: 0.5337 - val_accuracy: 0.6173 - val_loss: 1.6479 - val_top_k_categorical_accuracy: 0.9606\n",
      "Epoch 31/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8734 - Recall: 0.7403 - accuracy: 0.8053 - loss: 0.6315 - top_k_categorical_accuracy: 0.9836 - val_Precision: 0.7210 - val_Recall: 0.5740 - val_accuracy: 0.6476 - val_loss: 1.6609 - val_top_k_categorical_accuracy: 0.9419\n",
      "Epoch 32/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8743 - Recall: 0.7416 - accuracy: 0.8069 - loss: 0.6245 - top_k_categorical_accuracy: 0.9858 - val_Precision: 0.8670 - val_Recall: 0.4431 - val_accuracy: 0.6514 - val_loss: 1.0946 - val_top_k_categorical_accuracy: 0.9525\n",
      "Epoch 33/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8763 - Recall: 0.7414 - accuracy: 0.8087 - loss: 0.6250 - top_k_categorical_accuracy: 0.9846 - val_Precision: 0.7393 - val_Recall: 0.6538 - val_accuracy: 0.6936 - val_loss: 1.3388 - val_top_k_categorical_accuracy: 0.9691\n",
      "Epoch 34/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8735 - Recall: 0.7418 - accuracy: 0.8077 - loss: 0.6242 - top_k_categorical_accuracy: 0.9836 - val_Precision: 0.7270 - val_Recall: 0.6894 - val_accuracy: 0.7036 - val_loss: 1.7179 - val_top_k_categorical_accuracy: 0.9712\n",
      "Epoch 35/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8773 - Recall: 0.7467 - accuracy: 0.8097 - loss: 0.6300 - top_k_categorical_accuracy: 0.9855 - val_Precision: 0.7326 - val_Recall: 0.6360 - val_accuracy: 0.6807 - val_loss: 1.5387 - val_top_k_categorical_accuracy: 0.9606\n",
      "Test loss: 1.5386817455291748\n",
      "Test accuracy: 0.6807000041007996\n",
      "Test precision: 0.7325500845909119\n",
      "Test recall: 0.6359999775886536\n",
      "Test top-K categorical accuracy: 0.9606000185012817\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Define the model architecture for CIFAR-10\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=RMSprop(learning_rate=0.001), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd1443a1-f521-4478-9ba1-9cd6e14ea902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - Precision: 0.1806 - Recall: 2.6739e-04 - accuracy: 0.1378 - loss: 3.4205 - top_k_categorical_accuracy: 0.5800 - val_Precision: 0.5000 - val_Recall: 1.0000e-04 - val_accuracy: 0.2702 - val_loss: 3.1537 - val_top_k_categorical_accuracy: 0.7877\n",
      "Epoch 2/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.4931 - Recall: 0.0078 - accuracy: 0.2617 - loss: 3.1292 - top_k_categorical_accuracy: 0.7891 - val_Precision: 0.7557 - val_Recall: 0.0099 - val_accuracy: 0.3360 - val_loss: 2.9531 - val_top_k_categorical_accuracy: 0.8475\n",
      "Epoch 3/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.6222 - Recall: 0.0381 - accuracy: 0.3300 - loss: 2.9354 - top_k_categorical_accuracy: 0.8464 - val_Precision: 0.7213 - val_Recall: 0.0308 - val_accuracy: 0.3964 - val_loss: 2.7859 - val_top_k_categorical_accuracy: 0.8870\n",
      "Epoch 4/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.6287 - Recall: 0.0848 - accuracy: 0.3777 - loss: 2.7740 - top_k_categorical_accuracy: 0.8832 - val_Precision: 0.7114 - val_Recall: 0.0779 - val_accuracy: 0.4096 - val_loss: 2.6959 - val_top_k_categorical_accuracy: 0.8908\n",
      "Epoch 5/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.6468 - Recall: 0.1282 - accuracy: 0.4110 - loss: 2.6587 - top_k_categorical_accuracy: 0.8969 - val_Precision: 0.7381 - val_Recall: 0.1316 - val_accuracy: 0.4474 - val_loss: 2.5561 - val_top_k_categorical_accuracy: 0.9097\n",
      "Epoch 6/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.6663 - Recall: 0.1769 - accuracy: 0.4416 - loss: 2.5475 - top_k_categorical_accuracy: 0.9100 - val_Precision: 0.7341 - val_Recall: 0.2048 - val_accuracy: 0.4796 - val_loss: 2.4395 - val_top_k_categorical_accuracy: 0.9236\n",
      "Epoch 7/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.6893 - Recall: 0.2175 - accuracy: 0.4666 - loss: 2.4563 - top_k_categorical_accuracy: 0.9215 - val_Precision: 0.7630 - val_Recall: 0.2144 - val_accuracy: 0.5016 - val_loss: 2.3564 - val_top_k_categorical_accuracy: 0.9327\n",
      "Epoch 8/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.6928 - Recall: 0.2479 - accuracy: 0.4911 - loss: 2.3756 - top_k_categorical_accuracy: 0.9288 - val_Precision: 0.7535 - val_Recall: 0.2580 - val_accuracy: 0.5157 - val_loss: 2.2862 - val_top_k_categorical_accuracy: 0.9355\n",
      "Epoch 9/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7093 - Recall: 0.2730 - accuracy: 0.5043 - loss: 2.3128 - top_k_categorical_accuracy: 0.9319 - val_Precision: 0.7314 - val_Recall: 0.2815 - val_accuracy: 0.5188 - val_loss: 2.2435 - val_top_k_categorical_accuracy: 0.9390\n",
      "Epoch 10/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.7089 - Recall: 0.2898 - accuracy: 0.5152 - loss: 2.2659 - top_k_categorical_accuracy: 0.9367 - val_Precision: 0.7702 - val_Recall: 0.3026 - val_accuracy: 0.5414 - val_loss: 2.1771 - val_top_k_categorical_accuracy: 0.9429\n",
      "Epoch 11/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7236 - Recall: 0.3171 - accuracy: 0.5321 - loss: 2.2035 - top_k_categorical_accuracy: 0.9378 - val_Precision: 0.7597 - val_Recall: 0.3326 - val_accuracy: 0.5513 - val_loss: 2.1176 - val_top_k_categorical_accuracy: 0.9451\n",
      "Epoch 12/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7312 - Recall: 0.3317 - accuracy: 0.5429 - loss: 2.1533 - top_k_categorical_accuracy: 0.9435 - val_Precision: 0.7767 - val_Recall: 0.3429 - val_accuracy: 0.5667 - val_loss: 2.0610 - val_top_k_categorical_accuracy: 0.9495\n",
      "Epoch 13/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7430 - Recall: 0.3564 - accuracy: 0.5589 - loss: 2.0888 - top_k_categorical_accuracy: 0.9485 - val_Precision: 0.7664 - val_Recall: 0.3688 - val_accuracy: 0.5791 - val_loss: 2.0069 - val_top_k_categorical_accuracy: 0.9544\n",
      "Epoch 14/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7389 - Recall: 0.3666 - accuracy: 0.5587 - loss: 2.0502 - top_k_categorical_accuracy: 0.9502 - val_Precision: 0.7795 - val_Recall: 0.3787 - val_accuracy: 0.5909 - val_loss: 1.9660 - val_top_k_categorical_accuracy: 0.9558\n",
      "Epoch 15/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7502 - Recall: 0.3905 - accuracy: 0.5774 - loss: 1.9929 - top_k_categorical_accuracy: 0.9531 - val_Precision: 0.7710 - val_Recall: 0.3824 - val_accuracy: 0.5855 - val_loss: 1.9535 - val_top_k_categorical_accuracy: 0.9536\n",
      "Epoch 16/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7534 - Recall: 0.3959 - accuracy: 0.5854 - loss: 1.9490 - top_k_categorical_accuracy: 0.9545 - val_Precision: 0.7801 - val_Recall: 0.4137 - val_accuracy: 0.6093 - val_loss: 1.8678 - val_top_k_categorical_accuracy: 0.9615\n",
      "Epoch 17/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7587 - Recall: 0.4156 - accuracy: 0.5958 - loss: 1.9072 - top_k_categorical_accuracy: 0.9545 - val_Precision: 0.7870 - val_Recall: 0.4230 - val_accuracy: 0.6154 - val_loss: 1.8327 - val_top_k_categorical_accuracy: 0.9631\n",
      "Epoch 18/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7611 - Recall: 0.4268 - accuracy: 0.6032 - loss: 1.8680 - top_k_categorical_accuracy: 0.9568 - val_Precision: 0.7899 - val_Recall: 0.4350 - val_accuracy: 0.6204 - val_loss: 1.8155 - val_top_k_categorical_accuracy: 0.9602\n",
      "Epoch 19/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7666 - Recall: 0.4394 - accuracy: 0.6102 - loss: 1.8290 - top_k_categorical_accuracy: 0.9598 - val_Precision: 0.7875 - val_Recall: 0.4484 - val_accuracy: 0.6279 - val_loss: 1.7664 - val_top_k_categorical_accuracy: 0.9625\n",
      "Epoch 20/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7702 - Recall: 0.4503 - accuracy: 0.6176 - loss: 1.7914 - top_k_categorical_accuracy: 0.9623 - val_Precision: 0.7748 - val_Recall: 0.4583 - val_accuracy: 0.6290 - val_loss: 1.7438 - val_top_k_categorical_accuracy: 0.9652\n",
      "Epoch 21/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7740 - Recall: 0.4648 - accuracy: 0.6283 - loss: 1.7525 - top_k_categorical_accuracy: 0.9620 - val_Precision: 0.7900 - val_Recall: 0.4775 - val_accuracy: 0.6462 - val_loss: 1.6883 - val_top_k_categorical_accuracy: 0.9675\n",
      "Epoch 22/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7783 - Recall: 0.4823 - accuracy: 0.6358 - loss: 1.7063 - top_k_categorical_accuracy: 0.9660 - val_Precision: 0.8113 - val_Recall: 0.4741 - val_accuracy: 0.6537 - val_loss: 1.6525 - val_top_k_categorical_accuracy: 0.9685\n",
      "Epoch 23/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7828 - Recall: 0.4847 - accuracy: 0.6402 - loss: 1.6835 - top_k_categorical_accuracy: 0.9653 - val_Precision: 0.8038 - val_Recall: 0.4928 - val_accuracy: 0.6582 - val_loss: 1.6271 - val_top_k_categorical_accuracy: 0.9696\n",
      "Epoch 24/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.7889 - Recall: 0.4997 - accuracy: 0.6481 - loss: 1.6464 - top_k_categorical_accuracy: 0.9675 - val_Precision: 0.7948 - val_Recall: 0.5131 - val_accuracy: 0.6636 - val_loss: 1.5917 - val_top_k_categorical_accuracy: 0.9714\n",
      "Epoch 25/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.7905 - Recall: 0.5073 - accuracy: 0.6512 - loss: 1.6168 - top_k_categorical_accuracy: 0.9696 - val_Precision: 0.7800 - val_Recall: 0.5166 - val_accuracy: 0.6551 - val_loss: 1.5869 - val_top_k_categorical_accuracy: 0.9700\n",
      "Epoch 26/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7891 - Recall: 0.5167 - accuracy: 0.6603 - loss: 1.5823 - top_k_categorical_accuracy: 0.9698 - val_Precision: 0.7974 - val_Recall: 0.5210 - val_accuracy: 0.6675 - val_loss: 1.5505 - val_top_k_categorical_accuracy: 0.9733\n",
      "Epoch 27/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7947 - Recall: 0.5234 - accuracy: 0.6622 - loss: 1.5650 - top_k_categorical_accuracy: 0.9697 - val_Precision: 0.7929 - val_Recall: 0.5187 - val_accuracy: 0.6624 - val_loss: 1.5527 - val_top_k_categorical_accuracy: 0.9721\n",
      "Epoch 28/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.7947 - Recall: 0.5275 - accuracy: 0.6665 - loss: 1.5358 - top_k_categorical_accuracy: 0.9717 - val_Precision: 0.8083 - val_Recall: 0.5447 - val_accuracy: 0.6830 - val_loss: 1.4893 - val_top_k_categorical_accuracy: 0.9739\n",
      "Epoch 29/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.8036 - Recall: 0.5415 - accuracy: 0.6751 - loss: 1.5063 - top_k_categorical_accuracy: 0.9722 - val_Precision: 0.8035 - val_Recall: 0.5490 - val_accuracy: 0.6787 - val_loss: 1.4797 - val_top_k_categorical_accuracy: 0.9745\n",
      "Epoch 30/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.8056 - Recall: 0.5511 - accuracy: 0.6783 - loss: 1.4787 - top_k_categorical_accuracy: 0.9741 - val_Precision: 0.7936 - val_Recall: 0.5617 - val_accuracy: 0.6775 - val_loss: 1.4692 - val_top_k_categorical_accuracy: 0.9743\n",
      "Epoch 31/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8009 - Recall: 0.5479 - accuracy: 0.6800 - loss: 1.4613 - top_k_categorical_accuracy: 0.9733 - val_Precision: 0.8173 - val_Recall: 0.5671 - val_accuracy: 0.6936 - val_loss: 1.4130 - val_top_k_categorical_accuracy: 0.9770\n",
      "Epoch 32/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.8099 - Recall: 0.5669 - accuracy: 0.6892 - loss: 1.4170 - top_k_categorical_accuracy: 0.9768 - val_Precision: 0.8081 - val_Recall: 0.5773 - val_accuracy: 0.6994 - val_loss: 1.3917 - val_top_k_categorical_accuracy: 0.9766\n",
      "Epoch 33/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.8116 - Recall: 0.5709 - accuracy: 0.6933 - loss: 1.3995 - top_k_categorical_accuracy: 0.9766 - val_Precision: 0.8159 - val_Recall: 0.5783 - val_accuracy: 0.7050 - val_loss: 1.3730 - val_top_k_categorical_accuracy: 0.9773\n",
      "Epoch 34/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Precision: 0.8133 - Recall: 0.5762 - accuracy: 0.6954 - loss: 1.3827 - top_k_categorical_accuracy: 0.9767 - val_Precision: 0.8150 - val_Recall: 0.5829 - val_accuracy: 0.7017 - val_loss: 1.3629 - val_top_k_categorical_accuracy: 0.9773\n",
      "Epoch 35/35\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Precision: 0.8183 - Recall: 0.5830 - accuracy: 0.7029 - loss: 1.3567 - top_k_categorical_accuracy: 0.9781 - val_Precision: 0.8166 - val_Recall: 0.5852 - val_accuracy: 0.7083 - val_loss: 1.3400 - val_top_k_categorical_accuracy: 0.9771\n",
      "Test loss: 1.3400189876556396\n",
      "Test accuracy: 0.708299994468689\n",
      "Test precision: 0.8166341185569763\n",
      "Test recall: 0.5852000117301941\n",
      "Test top-K categorical accuracy: 0.9771000146865845\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define the model architecture for CIFAR-10\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(128, (3, 3), kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(256, (3, 3), kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Flatten(),\n",
    "    Dense(512, kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=SGD(learning_rate=0.001, momentum=0.9), \n",
    "    metrics=['accuracy', 'Precision', 'Recall', 'top_k_categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=35, validation_data=(x_test, y_test), verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test top-K categorical accuracy:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fec99a-0a94-4335-930e-4960f228bbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
